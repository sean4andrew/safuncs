---
title: "Testing Grounds"
output: 
  rmdformats::readthedown:
    code_download: true
date: '`r format(Sys.time(), "%d %B, %Y")`'
---

# Heading 1

methods are commonly categorized into two groups based on their objective namely to control for FWER (Family Wise Error Rate) or FDR (False Discovery Rate). Traditionally ___. FWER (e.g.method = ""). This method... It make sense when .... However,.... makese no sense. The FWER additionally suffers from XXX and also scalability problem. XXX compiled a list why these days there is a recommendation for FDR.. An example of advantage... ANother example... In the field of XXX.... FDR ditches the FWER idea and instead XXX. It lives in the alternate (when there is already an effect). The concept is XX which makes much more sense. The FDR (BH)generally has greater power than XXX, guaranteeing a maximum of 5%. It is not yet investigated how bad XX in our situations (to be investigated). The BHY, but XXX quite strong. 

```{r}
#remotes::install_github("sean4andrew/safuncs")
#upercent_signif_seackage()

library(ggplot2)
library(dplyr)
library(magrittr)

setwd("C:/Users/sean4/Downloads")
multivar_db_ex = read.csv(file = "U21038-24 scoring.csv") #minimum argument
multivar_db_ex$Fruits = rep(rep(c("Orange", "Apple"), each = 4), times = 6)
multivar_db_ex[10, 6] = NA #for testing purposes
multivar_db_ex = multivar_db_ex[,-c(1, 3, 11)] 
```

```{r}
MultiVar(multivar_db = multivar_db_ex,
         values_cols = 2:8,
         factors_cols = c(1, 9), 
         factors_facet = c("col1", "col2"),
         factors_pool = c("col1", "col2"), #Only relevant in two-factor scenarios, otherwise argument is ignored. A character vector representing the column(s) with factor levels to facet across in additionally generated plots. Choose any number from "col1" and "col2" which refers to ___, respectively. Defaults to "facet2" as it is assumed that the   .
         pca_labels = "var",
         univariate_tests = TRUE) # A character string describing the labels to add to all 'existing' PCA plots (as determined by prior arguments). Choose any number from "var" and "ind" which refers to xxx, respectively.
```

```{r}
MultiVar(multivar_db = iris,
         values_cols = 1:4,
         factors_cols = 5,
         pca_ellipse = c("none", "confidence", "distribution", "convexhull"))
```


```{r}
new_iris = iris
new_iris[1:25, 1] = NA
MultiVar(multivar_db = new_iris,
         values_cols = 1:4,
         factors_cols = 5,
         plot_out_R = TRUE)
#rnings(RVAideMemoire::adonis.II(formula = cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species,
#                                                         data = iris, method = "euc"))
# 
# iris_scaled = scale(iris[, 1:4])
# iris_scaled = data.frame(Species = iris$Species, iris_scaled)
# 
# options(contrasts = c("contr.sum", "contr.poly"))
# lda_mod = MASS::lda(formula = Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
#                             data = iris_scaled)
```
```{r}
Test = function(){
  overwrite = menu(c("Yes", "No"), title = "A MultiVar Word document with the same filename as one to be written was found in your working directory. Do you want to proceed and overwrite it?")
  if(overwrite == 2) {stop("Function stopped.")}
  print("passed")
}

Test()
```


```{r MultiVar()}
MultiVar = function(multivar_db = multivar_db_ex,
values_cols = 4:10,
factors_cols = c(2, 12),
factors_pool = c("col1", "col2"),
factors_facet = c("col1", "col2"),
pca_ellipse = c("none", "confidence"),
pca_labels = NULL,
missing_method = "imputation",
scale = TRUE,
center = TRUE,
boxplot_filled = TRUE,
boxplot_x_angle = NULL,
boxplot_x_lab = FALSE,
colours = NULL,
univariate_tests = FALSE,
plot_out_png = FALSE,
plot_out_pptx = FALSE,
plot_out_R = FALSE){
# iris[1:25, 1] = NA
# 
# multivar_db = iris
# values_cols = 1:4
# factors_cols = 5
# factors_pool = c("col1", "col2")
# factors_facet = c("col1", "col2")
# pca_ellipse = c("none", "confidence")
# pca_labels = NULL
# missing_method = "imputation"
# scale = TRUE
# center = TRUE
# boxplot_filled = TRUE
# boxplot_x_angle = NULL
# boxplot_x_lab = FALSE
# boxplot_x_wrap = NULL
# colours = NULL
# univariate_tests = FALSE
# plot_out_png = FALSE
# plot_out_pptx = FALSE
# plot_out_R = FALSE

  print("This might take a while...")
  
  # Initialize and define objects
  results_doc = officer::read_docx()
  results_doc_boxplot = officer::read_docx()
  tempf = tempfile(fileext = ".docx")
  pca_list = list(list())
  boxplot_list = list(list())
  dataframe_list = list()
  boxplot_name_vec = c()
  box_height2_vec = c()

  # Set path and file names
  if(plot_out_png == TRUE) {
    img_path = file.path(getwd(), paste("MultiVar PNG Figures", format(Sys.Date(), "%d%b%Y")))
    suppressWarnings(dir.create(img_path))
  } else {
    img_path = file.path(tempdir(), "Temp MultiVar PNG Figures")
    suppressWarnings(dir.create(img_path))
  }
  
  if(plot_out_pptx == TRUE) {
    pptx_name = paste(sep = "", "MultiVar Editable Figures ",
                    format(Sys.Date(), "%d%b%Y"), ".pptx")
    if(file.exists(pptx_name)) {
      file.remove(pptx_name)
    }
  }

  # Get matrix of values
  matrix_values_ori = multivar_db[, values_cols]
  matrix_values = multivar_db[, values_cols]

  # Validation check(s)
  if(length(values_cols) < 2){stop("At least two columns are needed with variable values for proper multivariate analysis. Please add more columns to the 'values_cols' argument.")}
  if(length(factors_cols) > 2){stop("A maximum of two factors are allowed. Please reduce the number of columns specified in 'factors_cols' to ≤ 2.")}
  if(length(factors_cols) != 2) {factors_pool <- "none"}
  if(length(factors_cols) != 2) {factors_facet <- "none"}

  # Address NAs in matrix values
  if(missing_method == "imputation") {
    if(sum(is.na(matrix_values)) > 0) { 
      matrix_values = data.frame(missMDA::imputePCA(matrix_values, ncp = missMDA::estim_ncpPCA(matrix_values)$ncp)$completeObs)
    }
  }
  if(missing_method == "na_omit") {
    multivar_db_ori = multivar_db
    multivar_db = multivar_db[stats::complete.cases(matrix_values),]
    matrix_values = multivar_db[, values_cols]
  }

  # Get PC values
  pc_values = stats::prcomp(matrix_values, scale = scale, center = center)
  matrix_values$PC1 = PC1 <- pc_values$x[, 1]
  matrix_values$PC2 = PC2 <- pc_values$x[, 2]

  # Get loadings
  load_db = data.frame(load1 = load1 <- pc_values$rotation[, 1] * pc_values$sdev[1],
                       load2 = load2 <- pc_values$rotation[, 2] * pc_values$sdev[2],
                       vars = stringr::str_wrap(width = 15, gsub("\\.", " ", rownames(pc_values$rotation))))

  # Create factor conditions
  full_conds = c("none", "pooled1", "pooled2", "facet1", "facet2")
  treatment_conds = as.vector(factor(unique(c("none", gsub("col", "pooled", factors_pool),
                                              gsub("col", "facet", factors_facet))), levels = full_conds))

  # Create base database for plotting
  plot_db = cbind(multivar_db[, factors_cols, drop = FALSE], matrix_values)

  # Create base PCA plot
  pca_plot_base = ggplot(data = plot_db) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_vline(xintercept = 0, linetype = "dashed") +
    theme_minimal() +
    xlab(paste("Principal Component 1 (", round(summary(pc_values)$importance[2, 1] * 100, 1), "%)", sep = "")) +
    ylab(paste("Principal Component 2 (", round(summary(pc_values)$importance[2, 2] * 100, 1), "%)", sep = "")) +
    theme(axis.line = element_line(color = "black", linewidth = 0.4),
          strip.background = element_rect(fill = "grey", color = NA))

  # Create base boxplot
  boxplot = ggplot() +
    geom_boxplot(size = 0.8, outlier.size = -1) +
    geom_jitter(height = 0, width = 0.2, shape = 21) +
    theme_minimal() +
    theme(axis.line = element_line(color = "black", linewidth = 0.4),
          strip.background = element_rect(fill = "grey", colour = NA),
          axis.text.x = element_text(hjust = 0.5))
  if(!is.null(boxplot_x_angle)) {boxplot <- boxplot + theme(axis.text.x = element_text(angle = boxplot_x_angle, hjust = 1))}
  if(!is.null(boxplot_x_wrap)) {boxplot <- boxplot + scale_x_discrete(labels = scales::wrap_format(boxplot_x_wrap))}

  # Colour plots if applicable
  if(!is.null(colours)){
    pca_plot_base = pca_plot_base + 
      scale_color_manual(values = colours) +
      scale_fill_manual(values = colours)
    
    boxplot = boxplot +
      scale_color_manual(values = colours) + 
      scale_fill_manual(values = colours)
  }
  
  # Set default plot dimensions
  pca_width = 6.3
  pca_height = 4.45
  varplot_width = 6.4
  varplot_height = 4.5

  # Create multiple plots (potentially) to deal with multi factor scenarios
  for(treatment_conds_i in treatment_conds) {

    # Create different databases for plotting in different factor scenarios
    if(treatment_conds_i == "none") {
      plot_db$base_factor = interaction(multivar_db[, factors_cols], sep = " & ")
      base_factor_name = ifelse(length(factors_cols) == 1,
                                colnames(multivar_db)[factors_cols], "Combination")
    }
    if(treatment_conds_i %in% c("facet2", "pooled2")) {
      plot_db$base_factor = multivar_db[, factors_cols[1]]
      plot_db$second_factor = multivar_db[, factors_cols[2]]
      base_factor_name = gsub("\\.", " ", colnames(multivar_db)[factors_cols[1]])
      second_factor_name = gsub("\\.", " ", colnames(multivar_db)[factors_cols[2]])
    }
    if(treatment_conds_i %in% c("facet1", "pooled1")) {
      plot_db$base_factor = multivar_db[, factors_cols[2]]
      plot_db$second_factor = multivar_db[, factors_cols[1]]
      base_factor_name = gsub("\\.", " ", colnames(multivar_db)[factors_cols[2]])
      second_factor_name = gsub("\\.", " ", colnames(multivar_db)[factors_cols[1]])
    }

    # Create facet dimensions depending on treatment_conds_i
    facet_num = ifelse(treatment_conds_i %in% c("none", "pooled2", "pooled1"),
                       length(values_cols),
                       length(unique(plot_db$second_factor)))
    facet_col = ifelse(facet_num %in% 1:3, 2, 3)
    facet_row = ceiling(facet_num / facet_col)

    # Modify PCA Plot based on treatment_conds_i
    pca_plot = pca_plot_base
    pca_plot$data = plot_db
    pca_plot$mapping = aes(x = PC1, y = PC2, colour = base_factor, fill = base_factor)
    pca_plot$guides = guides(colour = guide_legend(base_factor_name), fill = guide_legend(base_factor_name),
                             shape = guide_legend(base_factor_name))
    if(length(unique(plot_db$base_factor)) <= 6) {pca_plot$layers[[1]] <- geom_point(aes(shape = base_factor), size = 2)}
    if(length(unique(plot_db$base_factor)) > 6) {pca_plot$layers[[1]] <- geom_point(size = 2)}

    # Add PCA labels
    if("ind" %in% pca_labels) {
      pca_plot = pca_plot + ggrepel::geom_text_repel(show.legend = FALSE, max.overlaps = 20, aes(label = rownames(plot_db)))
    }
    if("var" %in% pca_labels) {
      # Calculate arrow length multiplier as in factoextra::fviz_pca_biplot()
      r0.7 = min((max(PC1) - min(PC1)/(max(load1) - min(load1))), (max(PC2) - min(PC2)/(max(load2) - min(load2)))) * 0.7
      pca_plot$layers = append(pca_plot$layers, geom_segment(data = load_db,
                                                             aes(fill = NULL, color = NULL, x = 0, y = 0,
                                                                 xend = load1 * r0.7, yend = load2 * r0.7),
                                                             color = "black", alpha = 0.8,
                                                             arrow = arrow(length = unit(0.2, "cm"), type = "open"),
                                                             show.legend = FALSE), after = 0)
      text_size_algo = ifelse(treatment_conds_i %in% c("none", "pooled2", "pooled1"),
                              3, 3.4 - (0.6 * facet_col))
      pca_plot = pca_plot + ggrepel::geom_text_repel(show.legend = FALSE, max.overlaps = 20,
                                                     data = load_db, aes(fill = NULL, color = NULL,
                                                                         x = load1 * r0.7, y = load2 * r0.7,
                                                                         label = vars),
                                                     color = "black", size = text_size_algo)
    }

    # Add PCA facets
    if(treatment_conds_i %in% c("facet2", "facet1")) {
      pca_plot = pca_plot + facet_wrap(~ second_factor, ncol = facet_col, nrow = facet_row)

      # Set plot height based on facet
      pca_height = 1.8 + 1.2 * facet_row
    }

    # Add ellipses and store PCA plots in a list
    if("none" %in% pca_ellipse) {pca_list[["none"]][[treatment_conds_i]] <- pca_plot}
    if("confidence" %in% pca_ellipse) {pca_list[["confidence"]][[treatment_conds_i]] <- pca_plot + ggpubr::stat_conf_ellipse(geom = "polygon", alpha = 0.15)}
    if("distribution" %in% pca_ellipse) {pca_list[["distribution"]][[treatment_conds_i]] <- pca_plot + ggplot2::stat_ellipse(type = "norm", geom = "polygon", alpha = 0.15)}
    if("convexhull" %in% pca_ellipse) {pca_list[["convexhull"]][[treatment_conds_i]] <- pca_plot + ggpubr::stat_chull(geom = "polygon", alpha = 0.15)}

    # Save PCA plots
    for(ellipse_i in pca_ellipse) {
      pca_name = paste("PCA", ifelse(treatment_conds_i == "none", "",
                                     paste(" Facet-", second_factor_name, sep = "")),
                       " Ellipse-", tools::toTitleCase(ellipse_i), sep = "")
      if(treatment_conds_i %in% c("pooled2", "pooled1")) {
        pca_name = paste("PCA Pooled Across-", second_factor_name, " Ellipse-", tools::toTitleCase(ellipse_i), sep = "")
      }

      if(plot_out_pptx){
        eoffice::topptx(figure = pca_list[[ellipse_i]][[treatment_conds_i]],
                        filename = pptx_name,
                        width = pca_width, height = pca_height, append = TRUE)
      }
      ggsave(plot = pca_list[[ellipse_i]][[treatment_conds_i]], filename = paste(sep = "", pca_name, ".png"),
             path = img_path, dpi = 600, width = pca_width, height = pca_height)
      results_doc = officer::body_add_img(x = results_doc, sr = file.path(img_path, paste(pca_name, ".png", sep = "")),
                                          width = pca_width, height = pca_height) %>%
        officer::body_add_par(value = pca_name, style = "graphic title") %>%
        officer::body_add_par("")
      if((last(treatment_conds) == treatment_conds_i) & (last(pca_ellipse) == ellipse_i)){} else {
        results_doc <- results_doc %>% officer::body_add_par("")
      }
    }

    # Create variables plot, contributions table & variable correlations plot
    if(last(treatment_conds) == treatment_conds_i) {
      # Note for PCA
      results_doc = results_doc %>%
        officer::body_add_par(paste(sep = "", "The ", round(summary(pc_values)$importance[2, 1] * 100, 1), "% and ",
                                    round(summary(pc_values)$importance[2, 2] * 100, 1), "% values in the axes of the figures above describe the percent variation in the data explained by the first and second principal components, respectively."), style = "Normal") %>%
        officer::body_add_par("") %>%
        officer::body_add_par("")

      # Create variable plots
      varplot_name = "Correlation of Variables to PCs"
      varplot = factoextra::fviz_pca_var(pc_values, repel = TRUE) +
        xlab(expression(paste(sep = "", "Correlation (", italic(r), ") to PC1"))) +
        ylab(expression(paste(sep = "", "Correlation (", italic(r), ") to PC2"))) +
        theme(plot.title = element_blank(),
              axis.line = element_line(color = "black", linewidth = 0.4),
              plot.margin = unit(c(0, 0.18, 0, 0.18), "in"))
      varplot_layer3 = varplot$layers[[3]]
      varplot$layers[[3]] = ggrepel::geom_text_repel(data = varplot$data,
                                                     aes(x = x, y = y,
                                                         label = stringr::str_wrap(gsub("\\.", " ", name), width = 15)),
                                                     nudge_x = 0, nudge_y = 0, size = 3.75, color = "darkblue",
                                                     box.padding = 0, min.segment.length = 0.3, segment.colour = "darkblue")
      varplot$layers[[1]] = varplot_layer3

      # Save plot
      if(plot_out_pptx == TRUE) {
        eoffice::topptx(figure = varplot, filename = pptx_name,
                        width = varplot_width, height = varplot_height, append = TRUE)
      }
      ggsave(plot = varplot, filename = paste(sep = "", varplot_name, ".png"), path = img_path,
             dpi = 600, width = varplot_width, height = varplot_height)

      # Create correlations table
      correl_db = data.frame(cor(matrix_values)) %>% tibble::rownames_to_column(" ")
      colnames(correl_db) = gsub("\\.", " ", colnames(correl_db))
      correl_db[, 1] = gsub("\\.", " ", correl_db[, 1])

      correl_tab = flextable::flextable(correl_db) %>%
        flextable::set_caption(caption = "Table 1. Pearson correlation coefficient (r) between variables and principal components") %>%
        flextable::colformat_double(digits = ifelse(length(values_cols) < 5, 4, 3)) %>%
        flextable::line_spacing(space = ifelse(length(values_cols) < 5, 1, 0.8), part = "all") %>%
        flextable::fontsize(size = ifelse(length(values_cols) < 5, 11, 9), part = "all") %>%
        flextable::set_table_properties(layout = "autofit", width = 1)

      # Create contribution table
      contrib_db = data.frame(Variable = gsub("\\.", " ", names(pc_values$rotation[,1])),
                              ContributionPC1 = as.vector(100 * pc_values$rotation[,1]^2),
                              EigenvectorPC1 = as.vector(pc_values$rotation[,1]),
                              ContributionPC2 = as.vector(100 * pc_values$rotation[,2]^2),
                              EigenvectorPC2 = as.vector(pc_values$rotation[,2])) %>% dplyr::arrange(desc(ContributionPC1))

      contrib_tab = flextable::flextable(contrib_db) %>%
        flextable::set_caption(caption = "Table 2. Contribution of variables to principal components") %>%
        flextable::set_table_properties(layout = "autofit", width = 1)

      # Save the three results (1 plots, 2 table) in the word document
      results_doc = results_doc %>%
        officer::body_add_img(sr = file.path(img_path, paste(varplot_name, ".png", sep = "")),
                              width = varplot_width, height = varplot_height) %>%
        officer::body_add_par(value = varplot_name, style = "graphic title") %>%
        officer::body_add_break() %>%
        flextable::body_add_flextable(value = correl_tab, align = "left", topcaption = TRUE, split = FALSE) %>%
        officer::body_add_break() %>%
        flextable::body_add_flextable(value = contrib_tab, align = "left", topcaption = TRUE, split = FALSE) %>%
        officer::body_add_par("The contribution describes how much (in %) of the PC is composed of that variable; a more precise definition is that it is the variable's eigenvector^2 when the sum of eigenvectors^2 (over all variables) is equal to 1 (100%) for each PC (this condition is implicit in PCA). The eigenvector represents both the magnitude and direction of change of the principal component for each unit increase of the variable. This variable is in the standardized scale (z-score normalized) if scale and center arguments are set to TRUE.", style = "Normal") %>%
        officer::body_add_break()
    }

    # Create long database for boxplots
    if(missing_method == "na_omit") {
      if(treatment_conds_i %in% c("none")){base_factor <- interaction(multivar_db_ori[, factors_cols], sep = " & ")}
      if(treatment_conds_i %in% c("pooled2", "facet2")) {
        base_factor = multivar_db_ori[, factors_cols[1]]
        second_factor = multivar_db_ori[, factors_cols[2]]
      }
      if(treatment_conds_i %in% c("pooled1", "facet1")) {
        base_factor = multivar_db_ori[, factors_cols[2]]
        second_factor = multivar_db_ori[, factors_cols[1]]
        }
    } else {
      base_factor = plot_db$base_factor
      second_factor = plot_db$second_factor}

    # Create long database from plot_db
    plot_db_long = data.frame(cbind(base_factor = base_factor,
                                    second_factor = if(treatment_conds_i == "none"){"none"} else {second_factor},
                                    matrix_values_ori) %>%
                                tidyr::pivot_longer(cols = 3:(2 + length(values_cols)),
                                                    names_to = "variable", values_to = "values"))
    plot_db_long$variable = gsub("\\.", " ", plot_db_long$variable)

    # Create boxplots with variables facet
    point_size_algo = 2.4 - (facet_col * length(unique(plot_db_long$base_factor)) - 4)/ (33 / 0.9)
    box_height = 1.7 + 1.1 * facet_row

    boxplot$data = plot_db_long
    boxplot$mapping = aes(y = values, x = base_factor, colour = base_factor)
    boxplot$guides = guides(colour = guide_legend(base_factor_name), fill = guide_legend(base_factor_name),
                            shape = guide_legend(base_factor_name))
    boxplot$layers[[2]] = geom_jitter(height = 0, width = 0.2, shape = 21, size = point_size_algo)
    boxplot = boxplot +
      facet_wrap(~ variable, ncol = facet_col, nrow = facet_row, scales = "free_y") +
      ylab("Value") +
      theme(plot.margin = unit(c(0.07, 0.09, 0.07, 0.09), "in"),
            strip.text = element_text(size = 8.8, margin = margin(0.155, 0.1, 0.155, 0.1, unit = "cm")),
            strip.background = element_rect(fill = "grey", color = NA))
    if(boxplot_x_lab == TRUE) {boxplot <- boxplot + xlab(base_factor_name)}
    if(boxplot_filled == TRUE) {boxplot$mapping <- aes(y = values, x = base_factor, fill = base_factor)}

    if(treatment_conds_i %in% c("none", "pooled2", "pooled1")) {
      
      # Save the boxplots with variables facet
      boxplot_name = ifelse(treatment_conds_i == "none", "Boxplot of Values Facet-Variables",
                            paste("Boxplot of Values Facet-Variables Pooled Across-", second_factor_name, sep = ""))
      boxplot_list[[treatment_conds_i]][["facetvariables"]] = boxplot

      if(plot_out_pptx == TRUE) {
        eoffice::topptx(figure = boxplot, filename = pptx_name,
                        width = 6.4, height = box_height, append = TRUE)
      }
      ggsave(plot = suppressWarnings(boxplot), filename = paste(sep = "", boxplot_name, ".png"), path = img_path,
             dpi = 600, width = 6.4, height = box_height)
      results_doc_boxplot = results_doc_boxplot %>%
        officer::body_add_img(sr = file.path(img_path, paste(sep = "", boxplot_name, ".png")),
                              width = 6.4, height = box_height) %>%
        officer::body_add_par(value = boxplot_name, style = "graphic title") %>%
        officer::body_add_par("") %>%
        officer::body_add_par("")
      
    }

    
    # Create boxplots without variables facet, for each separate variable.
    box_num = length(unique(plot_db_long$base_factor)) * ifelse(treatment_conds_i %in% c("facet1", "facet2"), facet_col, 1)
    box_row = ifelse(treatment_conds_i %in% c("facet1", "facet2"), facet_row, 1)
    point_size_algo = 3 - (box_num - 2)/ 24
    
    box_height2 = 2.05 + (1.1 * box_row) + ifelse(box_num <= 6, 0.4, 0)
    for(values_cols_i in values_cols) {
      varname = gsub("\\.", " ", colnames(multivar_db)[values_cols_i])

      # Filter for a variable
      plot_db_long_filtered = plot_db_long[plot_db_long$variable == varname, ]

      # Change boxplot data, point size, facet and names
      boxplot = boxplot +
        ylab(varname) +
        theme(strip.text = element_blank(),
              strip.background = element_blank(),
              plot.margin = unit(c(0.0 + (0.04 * box_num), 0.25, 0.05 + (0.01 * box_num), 0.25), "in"))
      boxplot$data = plot_db_long_filtered
      boxplot$layers[[2]] = geom_jitter(height = 0, width = 0.2, shape = 21, size = point_size_algo)

      if(treatment_conds_i %in% c("facet2", "facet1")) {
        boxplot$facet = facet_wrap(~ second_factor, ncol = facet_col, nrow = facet_row)
        boxplot = boxplot +
          theme(strip.text = element_text(size = 8.8, margin = margin(0.155, 0.1, 0.155, 0.1, unit = "cm")),
                strip.background = element_rect(fill = "grey", color = NA),
                plot.margin = unit(c(0.0 + (0.04 * box_num), 0.25, 0.05 + (0.01 * box_num), 0.25), "in"))
        boxplot_name = paste("Boxplot of ", varname, " Facet-", second_factor_name, sep = "")
      }
      if(treatment_conds_i == "none") {boxplot_name <- paste("Boxplot of ", varname, sep = "")}
      if(treatment_conds_i %in% c("pooled2", "pooled1")) {boxplot_name <- paste("Boxplot of ", varname, " Pooled Across-", second_factor_name, sep = "")}
      boxplot_name_vec = c(boxplot_name_vec, boxplot_name)
      box_height2_vec = c(box_height2_vec, box_height2)

      # Save these boxplots
      boxplot_list[[treatment_conds_i]][[varname]] = boxplot
      if(plot_out_pptx == TRUE) {
        eoffice::topptx(figure = boxplot, filename = pptx_name,
                        width = 6.4, height = box_height2, append = TRUE)
      }
      ggsave(plot = suppressWarnings(boxplot), filename = paste(boxplot_name, ".png", sep = ""),
             dpi = 600, width = 6.4, height = box_height2, path = img_path)
    }
      
    # Add them to results_doc
    if(treatment_conds_i == last(treatment_conds)){
      i = 0
      for(boxplot_name_i in boxplot_name_vec) {
        i = i + 1
        results_doc_boxplot = results_doc_boxplot %>%
          officer::body_add_img(sr = file.path(img_path, paste(boxplot_name_i, ".png", sep = "")),
                                width = 6.4, height = box_height2_vec[i]) %>%
          officer::body_add_par(value = boxplot_name_i, style = "graphic title") %>%
          officer::body_add_par("") %>%
          officer::body_add_par("")
      }
    }

    # Create LDA, MANOVA and potentially ANOVA tables
    if(last(treatment_conds) == treatment_conds_i) {
      results_doc_boxplot = results_doc_boxplot %>% officer::body_add_break()

      # Create LDA table results
      lda_db = cbind(multivar_db[, factors_cols, drop = FALSE],
                     scale(matrix_values[,!colnames(matrix_values) %in% c("PC1", "PC2")],
                           scale = scale, center = center))
      factors_vec = paste(collapse = " * ", colnames(multivar_db[, factors_cols, drop = FALSE]))
      values_vec = paste(collapse = " + ", colnames(lda_db[, (1 + length(factors_cols)):ncol(lda_db)]))

      tab_counter = 2
      for(lda_factor in colnames(multivar_db[, factors_cols, drop = FALSE])){
        tab_counter = tab_counter + 1

        # Fit LDA mod
        lda_mod = MASS::lda(formula = as.formula(paste(lda_factor, "~", values_vec)),
                            data = lda_db)

        # Store LDA results in a table and list
        lda_contrib = (scale(lda_mod$scaling, F, sqrt(colSums(lda_mod$scaling^2))))^2
        lda_contrib_db = data.frame(Variable = gsub("\\.", " ", rownames(lda_contrib)),
                                    ContributionLD1 = 100 * lda_contrib[, 1],
                                    CoefficientLD1 = lda_mod$scaling[, 1])
        if(ncol(lda_contrib) > 1) {
          lda_contrib_db$ContributionLD2 = 100 * lda_contrib[, 2]
          lda_contrib_db$CoefficientLD2 = lda_mod$scaling[, 2]
        }

        lda_contrib_db = lda_contrib_db %>% dplyr::arrange(dplyr::desc(ContributionLD1))
        lda_contrib_tab = flextable::flextable(lda_contrib_db) %>%
          flextable::set_caption(caption = paste("Table ", tab_counter, ". Contribution of variables to linear discriminants of ",
                                                 lda_factor, sep = "")) %>%
          flextable::set_table_properties(layout = "autofit", width = 1)
        lda_exp = round(100 * (lda_mod$svd^2 / sum(lda_mod$svd^2)), 1)

        # Add results to officer
        results_doc_boxplot = results_doc_boxplot %>%
          flextable::body_add_flextable(value = lda_contrib_tab, align = "left", topcaption = TRUE, split = FALSE) %>%
          officer::body_add_par(value = paste(sep = "", "LD1 and LD2 explain ", lda_exp[1], "% and ", lda_exp[2],
                                              "% of the separation between ", lda_factor, ", respectively."), style = "Normal") %>%
          officer::body_add_par("")
      }

      results_doc_boxplot = results_doc_boxplot %>%
        officer::body_add_par("Tabulated values are based on Linear Discriminant Analysis (LDA). The contribution describes the percentage of the linear discriminant composed of that variable; a more exact definition is that it is the variable's coefficient of linear discriminant^2 when the sum of coefficients^2 (across variables) is normalized to 100%. The coefficient of linear discriminant describes the magnitude and direction of change in the linear discriminant score (towards a particular factor level) per unit increase of the variable. Apart from the coefficients relative signs and magnitude, they may be difficult to interpret without an associated LDA plot.", style = "Normal")

      # Get MANOVA results
      manova_db = cbind(multivar_db[, factors_cols, drop = FALSE],
                        matrix_values[,!colnames(matrix_values) %in% c("PC1", "PC2")])
      values_vec2 = paste("cbind(",
                          paste(collapse = ",", colnames(manova_db[, (1 + length(factors_cols)):ncol(manova_db)])),
                          ")", sep = "")

      options(contrasts = c("contr.sum", "contr.poly"))
      permanova = suppressWarnings(RVAideMemoire::adonis.II(formula = as.formula(paste(values_vec, "~", factors_vec)),
                                                            data = manova_db, method = "euclidean"))
      manova_mod = manova(formula = as.formula(paste(values_vec2, "~", factors_vec)),
                          data = manova_db)
      manova = car::Anova(type = 3, manova_mod)
      options(contrasts = c("contr.treatment", "contr.poly"))
      manova_p = suppressWarnings(as.numeric(na.omit(as.numeric(sub(".*\\s*(\\d+\\.[0-9e-]+)\\s*[*.]*",
                                                                    "\\1", capture.output(manova))))))
      # Create MANOVA table
      manova_db = data.frame(Factor = manova$terms[!manova$terms == "(Intercept)"],
                             PERMANOVA = as.numeric(na.omit(permanova$`Pr(>F)`)),
                             MANOVA = manova_p[!manova$terms == "(Intercept)"])
      manova_db$PERMANOVA = ifelse(manova_db$PERMANOVA < 0.001, formatC(manova_db$PERMANOVA, format = "e", digits = 4), manova_db$PERMANOVA)
      manova_db$MANOVA = ifelse(manova_db$MANOVA < 0.001, formatC(manova_db$MANOVA, format = "e", digits = 4), manova_db$MANOVA)

      manova_tab = flextable::flextable(manova_db) %>%
        flextable::set_caption(caption = paste("Table ", tab_counter + 1, ". MANOVA Results (p-values)", sep = "")) %>%
        flextable::set_table_properties(layout = "autofit", width = 1)

      # Run Univariate Tests
      if(univariate_tests == TRUE) {
        p_no_adj = c()

        # Get p-values for each variable
        varnames_vec = colnames(multivar_db[, values_cols, drop = FALSE])
        options(contrasts = c("contr.sum", "contr.poly"))
        for(values_vec_i in varnames_vec) {
          lm_mod = lm(data = multivar_db, formula = as.formula(paste(values_vec_i, "~", factors_vec)))
          Anova_res = car::Anova(lm_mod, type = 3, test.statistic = "F")
          p_no_adj = c(p_no_adj, as.numeric(na.omit(Anova_res$`Pr(>F)`[-1])))
        }
        options(contrasts = c("contr.treatment", "contr.poly"))
        p_bh = p.adjust(p_no_adj, method = "BH")

        # Create p-values table
        anova_fac = rownames(data.frame(Anova_res))[-c(1, length(rownames(data.frame(Anova_res))))]
        p_db = data.frame(Variable = rep(varnames_vec, each = length(anova_fac)),
                          Factor = rep(anova_fac, times = length(varnames_vec)),
                          Unadjusted = ifelse(p_no_adj < 0.001, formatC(p_no_adj, format = "e", digits = 4), p_no_adj))
        p_db$Variable = gsub("\\.", " ", p_db$Variable)
        if(length(factors_cols) == 1){p_db$FDR_Adjusted <- ifelse(p_bh < 0.001, formatC(p_bh, format = "e", digits = 4), p_bh)}
        colnames(p_db) = gsub("_", " ", colnames(p_db))

        p_tab = flextable::flextable(p_db) %>%
          flextable::set_caption(caption = paste("Table ", tab_counter + 2, ". ANOVA Results (p-values)", sep = "")) %>%
          flextable::set_table_properties(layout = "autofit", width = 1) %>%
          flextable::merge_v(j = "Variable")
      }

      results_doc_boxplot = results_doc_boxplot %>%
        officer::body_add_break() %>%
        flextable::body_add_flextable(value = manova_tab, align = "left", topcaption = TRUE, split = FALSE) %>%
        officer::body_add_par(ifelse(length(factors_cols) == 2, "PERMANOVA = permutational multivariate analysis of variance. The MANOVA conducted here uses the type 3 method for partitioning sums of squares between factors, while the PERMANOVA uses type 2 (because type 3 is not available). Typing is relevant only when there are multiple factors.", "PERMANOVA = Permutational Multivariate Analysis of Variance."), style = "Normal") %>%
        officer::body_add_par("") %>%
        officer::body_add_par(ifelse("0.001" %in% as.character(manova_db$PERMANOVA), "During testing, it was discovered that the PERMANOVA function used by MultiVar() shows p-values below 0.001 as only 0.001. To calculate the exact p-value, we need to make use of the F-value and degrees of freedom calculated by the PERMANOVA function for that factor. Please inform me if the exact p-value needs to be calculated. I have not written the code to address this limitation to save my time.", "")) %>%
        officer::body_add_par("")

      if(univariate_tests == TRUE) {
        results_doc_boxplot = results_doc_boxplot %>%
          officer::body_add_break() %>%
          flextable::body_add_flextable(value = p_tab, align = "left", topcaption = TRUE, split = FALSE)
        if(length(factors_cols) == 1) {
          results_doc_boxplot = results_doc_boxplot %>% officer::body_add_par("FDR Adjusted represents p-values adjusted for the False Discovery Rate, such that no more than 5% of discoveries are expected to be wrong. The adjustment is based on the Benjamini Hochberg procedure which assumes p-values are independent or positive-dependent. Our p-values may be negatively correlated although currently I do not see what type of data would produce that. At some point I might investigate the prevalence of this issue for ONDA datasets and assess its impact on FDR.")
        }
        if(length(factors_cols) == 2){
          results_doc_boxplot = results_doc_boxplot %>% officer::body_add_par("For two factor cases, Type 3 SS ANOVAs were conducted. P-values were not adjusted as it is unclear which adjustment method is appropriate (if any) when p-values are grouped (likely heavily correlated) by their factors.")
        }
        results_doc_boxplot = results_doc_boxplot %>%
          officer::body_add_par("") %>%
          officer::body_add_par("Because no FWER (Family-Wise Error Rate) adjustments were made on the p-values of the ANOVAs, they should not be used to make family level conclusions. For example, concluding that there is statistical evidence for any effect on the fish based on a significant p-value in an ANOVA. Conclusions made this way have a 34% chance of being positive (significant) even when the null is true (i.e. it is a false positive) for 8 independent ANOVAs. The false positive rate specifically is 1-(0.95^ANOVA_count) for the case of ANOVA with one factor. Please refer to the MANOVA results for a conclusion on the multivariate outcome.")
      }
    } 
  }

  # Save word document
  print(results_doc_boxplot, target = tempf)
  print(officer::body_add_docx(results_doc, src = tempf),
        target = paste(sep = "", "MultiVar Report ", format(Sys.Date(), "%d%b%Y"), ".docx"))

  # Delete temporary files
  file.remove(tempf)
  if(plot_out_png == FALSE) {unlink(img_path)}

  # Print plot output in R
  if(plot_out_R == TRUE) {
    return(list(pca = pca_list,
                correl = varplot,
                box = boxplot_list))
  }
}
```


```{r MultiVar() Examples}
#' # Below is a tutorial to help you create various reports using MultiVar(). Lets start 
#' # simple, with the aim of creating a report for the iris dataset which has only one
#' # factor (Species). We'll start by loading up the data using the code below:
#'  
data(iris)
#'
#' # Lets get a better look on how the data is laid out:
#' 
head(iris, n = 5)
#
str(iris)
#'
#' # From the above outputs, we can see which columns contain the factor and which 
#' # hold the dependent (outcome) variables. These are the minimum information needed by 
#' # MultiVar() for it to run properly. Lets give MultiVar() a shot!
#' 
MultiVar(multivar_db = iris,
         values_cols = 1:4,
         factors_cols = 5)
#'
#' # Above we have indicated the dataset is iris, while the dependent variables exist in
#' # columns #1 to #4, and the factor in column #5. Check out your working directory
#' # and you should see your first report created using MultiVar()! To see where your
#' # current working directory is, run the code below:
#' 
getwd()
#'
#' # Suppose we wanted to create a different, more pimped up PCA plot. We can achieve
#' # this by modifying the 'pca_' prefixed arguments.
#'
MultiVar(multivar_db = iris,
         values_cols = 1:4,
         factors_cols = 5,
         pca_ellipse = c("none", "confidence", "distribution", "convexhull"),
         pca_labels = c("var"),
         plot_out_R = TRUE)$pca
#'
#' # Note: The 'plot_out_R = TRUE' argument is used to obtain the plot output in R so
#' # that we can view them in this Example section, and the '$pca' code is used to limit
#' # the output to only pca plots.  
#' 
#' # Modification of the boxplots is also possible using the 'boxplot_' prefixed 
#' # arguments. Below, I added a tilt to the x-axis labels and removed the colour fill
#' # of the boxplots.
#'  
MultiVar(multivar_db = iris,
         values_cols = 1:4,
         factors_cols = 5,
         boxplot_x_angle = 45,
         boxplot_filled = FALSE,
         plot_out_R = TRUE)$box
#'
#' # If you are unsatisfied with the modification, plots can be saved as ggplot objects
#' # in R or in .pptx where they can be edited further:
#'  
box_SL = MultiVar(multivar_db = iris,
                  values_cols = 1:4,
                  factors_cols = 5,
                  boxplot_x_angle = 45,
                  boxplot_filled = FALSE,
                  plot_out_pptx = TRUE,
                  plot_out_R = TRUE)$box$none$'Sepal Length'

box_SL = box_SL + ggprism::theme_prism() + ggplot2::theme(strip.text.x = element_blank())
box_SL
#'
#' # Note: 'ggprism::theme_prism()' overwrites the 'boxplot_x_angle argument' which, if
#' # desired, has to be re-added using 'theme(axis.text.x = element_text(angle = 45))'.
#' 
#' # The plot can then be saved in various formats (e.g. tiff) with the desired
#' # dimensions and resolution: 
#' 
ggplot2::ggsave(filename = "box_SepalLength.tiff",
                plot = box_SL,
                width = 5,
                height = 5,
                dpi = 600)
#'
#' # The above examples assume a pretty well behaved dataset, but in real life the data
#' # can be accompanied with missing values (NAs). MultiVar() is built with this in mind 
#' # and supports two methods to address this issue. The argument 'missing_method = 
#' # "imputation"' instructs MultiVar() to create missing values using a PCA model 
#' # from missMDA::imputePCA(). This is the default method. Alternatively, the argument 
#' # "missing_method = "na_omit" can be used to remove entire rows of data with at least 
#' # one NA. This can be a costly action. Below, I show how the imputation method 
#' # effectively addresses missing values. To begin, I will add NAs to our iris dataset:
#' 
iris[1:25, 1] = NA
#'
#' # Next, lets run MultiVar()!
#'
MultiVar(multivar_db = iris,
         values_cols = 1:4,
         factors_cols = 5,
         missing_method = "imputation",
         plot_out_R = TRUE)$pca$none$none

#' # Notably, these pca plots do not look much different than before which is good as it
#' # indicates the imputation covers the randomly missing values without obvious bias.
#' 
#' ## TWO FACTOR CASES
#' # Two factor cases occur quite frequently in research, and MultiVar() can produce 
#' # plots tailored to that. At minimum, MultiVar() outputs plots with x-axis labels (or 
#' # legend labels) that represents different combinations of levels from the two 
#' # factors. This can mean a lot of levels which can look unsightly. To show how such a
#' # plot would look, I will load an example fish mucus dataset and run MultiVar(). 
#' # This dataset has one real factor (Treatment) and a fake, inserted factor (Fruits). 
#' 
data(multivar_db_ex)

head(multivar_db_ex, n = 5)

str(multivar_db_ex)

MultiVar(multivar_db = multivar_db_ex,
         values_cols = 2:8,
         factors_cols = c(1, 9),
         factors_pool = "none",
         factors_facet = "none")
#'
#' # The output is not printed here to keep things clean. Please see the report saved
#' # in your working directory!
#' 
#' # To reduce the number of legend or x-axis labels, simpler plots can be created with
#' # faceting or pooling of values across levels of a 'nuisance' factor (e.g. Fruits).
#' # The below code shows how to do this using the arguments 'factors_pool' and 
#' # 'factors_facet':
#'
MV_output = MultiVar(multivar_db = multivar_db_ex,
                     values_cols = 2:8,
                     factors_cols = c(1, 9),
                     factors_pool = "col2",
                     factors_facet = "col2",
                     plot_out_R = TRUE)

MV_output$pca$confidence$pooled2
MV_output$pca$confidence$facet2

#' # The above specifications for 'factors_pool' and 'factors_facet' tell MultiVar() to 
#' # facet and pool across levels of the second column in 'factors_cols' which
#' # corresponds to the ninth column in the dataset (Fruits). The default in MultiVar()
#' # for two factor scenarios is to consider this second column as the nuisance factor 
#' # to facet against.
#'
#' # In some cases, it may be relevant to facet and pool across the levels of the first
#' # factor (Treatment). Simply add "col1" to the input vectors!
#'
MV_output2 = MultiVar(multivar_db = multivar_db_ex,
                      values_cols = 2:8,
                      factors_cols = c(1, 9),
                      factors_pool = c("col1", "col2"),
                      factors_facet = c("col1", "col2"),
                      plot_out_R = TRUE)

MV_output2$pca$confidence$pooled1
MV_output2$pca$confidence$facet1
#'
#' # Lastly, in some cases we may want ANOVA outputs to assess the significance of 
#' # Treatment to each univariate outcome. The 'univariate_tests' argument should then 
#' # be set to TRUE: 
#' 
MultiVar(multivar_db = multivar_db_ex,
         values_cols = 2:8,
         factors_cols = c(1, 9),
         univariate_tests = TRUE)

#' # The table of ANOVA results can be viewed in the Word output in your working
#' # directory. That is the end of the tutorial! Hope it helps.
```

```{r Dump}
MultiVar(multivar_db = iris,
         values_cols = 1:4,
         factors_cols = 5,
         pca_ellipse = c("none", "confidence", "distribution", "convexhull"),
         pca_labels = c("var", "ind"),
         plot_out_R = TRUE)$pca
#'
#' # Note: The 'plot_out_R = TRUE' argument is used to obtain the plot output in R so
#' # that we can view them in this Example section, and the '$pca' code is used to limit
#' # the output to only pca plots.  
#'  
#' # Suppose some features of the pca plot are not desired, then they can be removed by
#' # deleting the responsible characters from the input vector. For example, we can 
#' # remove "ind" which represents the row number labels: 
#' 
```


```{r}
##################################################### Function 10 - Surv_Power() ####################################################

#' Calculate Power for Survival Studies
#'
#' @description Calculates the power of global and/or pairwise hypothesis tests for survival studies with support over a range of experimental designs. This versatility is enabled by the simulation-based approach of the power calculation, using the modular \code{Surv_Simul()} to simulate survival data from various experimental designs. Power calculations can be made to account for inter-tank variation using a mixed cox proportional hazards model (set the argument \code{model} to "coxph_glmm"). Additionally, power calculations can account for the multiplicity of pairwise comparisons using the \code{pairwise_corr} argument. Users can compare power across different experimental designs by specifying each as a list element in \code{Surv_Simul()}. The results are returned as dataframes and plots.
#'
#' @details Power calculation follows the standard procedure for simulation approaches. First, the user simulates hypothetical future sample sets using \code{Surv_Simul()}. For each sample set, a p-value is calculated by \code{Surv_Power()}. The percentage of p-values below 0.05 (positives) were then calculated, representing power. The percent positives can also represent false positive rate if the population/truth from which different treatments are simulated are identical.
#'
#' @param simul_db A dataframe containing the simulated survival sample sets generated from \code{Surv_Simul()}.
#' @param global_test A character vector representing the method(s) used for global hypothesis testing of significance of Trt.ID. Methods available are: 'logrank', 'wald', 'score', 'LRT'. 'logrank' represents the global logrank test of significance. The latter three methods are standard global hypothesis testing methods for model fits. They are only available when the argument \code{model} is specified (i.e. not NULL).'wald' represents the Wald Chisquare Test (also known as joint test) which assesses whether model parameters (log(hazard ratio)) are significantly different than 0 (i.e. HRs ≠ 1). Wald test can be done for various cox-proportional hazards model that could be relevant to our studies (glm, glmm, and gee). Due to its broad applicability, while also producing practically the same p-value (most of the time) compared to the other two test for models, 'wald' is recommended of the three. 'score' represents the Lagrange multiplier or Score test. 'LRT' represents the likelihood ratio test. Defaults to 'logrank' for now due to its ubiquity of use.
#' @param model A character vector representing the model(s) to fit for hypothesis testing. Models available are: 'coxph_glm' and 'coxph_glmm'. 'coxph_glm' represents the standard cox proportional hazard model fitted using \code{survival::coxph()} with Trt.ID as a fixed factor. 'coxph_glmm' represents the mixed cox proportional hazard model fitted using \code{coxme::coxme()} with Trt.ID as a fixed factor and Tank.ID as a random factor to account for inter-tank variation. Defaults to NULL where no model is used for hypothesis tests.
#' @param pairwise_test A character vector representing the method(s) used for pairwise comparisons. Use "logrank" to calculate power for logrank tests comparing different treatments. Use "EMM" to calculate power using Estimated Marginal Means based on model estimates (from 'coxph_glm' and/or 'coxph_glmm'). Defaults to "logrank".
#' @param pairwise_corr A character vector representing the method(s) used to adjust p-values for multiplicity of pairwise comparisons. The adjustment method affects power of the pairwise comparisons. Methods available are: "tukey", "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", and "none". In \bold{Details}, I discuss categories of the adjustment methods and provided a recommendation for "BH". Defaults to "none" for now.
#' @param data_out Whether to output dataframe(s) containing the power values calculated for the global and/or pairwise hypothesis tests. Defaults to TRUE.
#' @param plot_out Whether to display plot(s) illustrating power from global and/or pairwise hypothesis tests. Defaults to TRUE
#' @param plot_lines Whether to plot lines connecting points of the same "group" in the plot output. Defaults to TRUE.
#' @param xlab A string representing the x-axis title. Defaults to "List Element #".
#' @param xnames Vector of names for x-axis labels. Defaults to NULL where names are the list element numbers from \code{Surv_Gen()}.
#' @param plot_save Whether to save plots as a .tiff. Defaults to TRUE.
#'
#' @return Output. An SE for proportions (calculated using the binomial formula)
#'
#' @import magrittr
#' @import ggplot2
#'
#' @export
#'
#' @seealso \href{https://sean4andrew.github.io/safuncs/reference/Surv_Power.html}{Link} for web documentation.
#'
#' @examples
Surv_Power = function(simul_db = simul_db_ex,
                      global_test = "logrank", #selection(s) c("wald", "score", "LRT", "logrank")
                      model = NULL, #selection(s) from c("coxph_glm", "coxph_glmm", NULL). Defaults to NULL
                      pairwise_test = "logrank", #selection(s) c("EMM" or "logrank")
                      pairwise_corr = "none", #selection of c("tukey", "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "none").
                      plot_out = TRUE,
                      plot_lines = FALSE,
                      xlab = "List Element #",
                      xnames = NULL,
                      plot_save = TRUE){

  #Track time elapsed
  time_start = Sys.time()

  #Convert NULL pairwise_corr into "none"
  if(is.null(pairwise_corr)){pairwise_corr <- "none"}

  #Standardize simul_db as dataframe
  if(!is.data.frame(simul_db)){simul_db = data.frame(simul_db$simul_surv_db)}

  #Add a value of 1 for column list_element_num in case no value is present in simul_db
  if(!"list_element_num" %in% colnames(simul_db)){simul_db$list_element_num <- 1}

  #Validation checks (stops)
  if(sum(!global_test %in% c("logrank", "wald", "score", "LRT")) > 0) {
    stop(paste("The", global_test[!global_test %in% c("logrank", "wald", "score", "LRT")][1], "global test method is not in the list supported by Surv_Power(). Select any amount from 'logrank', 'wald', 'score', and/or 'LRT'. For no global test to be done, select NULL. "))
  }

  if(sum(!model %in% c("coxph_glm", "coxph_glmm")) > 0) {
    stop(paste("The", model[!model %in% c("coxph_glm", "coxph_glmm")][1], "model is currently not in the list supported by Surv_Power(). Select any amount from 'coxph_glm' and/or 'coxph_glmm'. For no model to be fitted, select NULL."))
  }

  if(sum(!pairwise_test %in% c("logrank", "EMM")) > 0) {
    stop(paste("The", pairwise_test[!pairwise_test %in% c("logrank", "EMM")][1], "pairwise test method is not in the list supported by Surv_Power(). Select any amount from 'logrank' and/or 'EMM'. For no pairwise test to be done, select NULL."))
  }

  pairwise_corr_options = c("tukey", "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "none")
  if(sum(!pairwise_corr %in% pairwise_corr_options) > 0) {
    stop(paste("The", pairwise_corr[!pairwise_corr %in% pairwise_corr_options][1], "pairwise correction method is not in the list supported by Surv_Power(). Select any amount from 'tukey', 'holm', 'hochberg', 'hommel', 'bonferroni', 'BH', 'BY', and/or 'none'."))
  }

  #Initialize objects to store values
  power_glob = data.frame()
  power_pair = data.frame()
  prog = 0

  #Subset data by list_element_num. Loop through each.
  for(ele_num in unique(simul_db$list_element_num)) {
    simul_db_temp0 = simul_db[simul_db$list_element_num == ele_num,] #filter for ele_num

    #Clear stored p_values for every ele_num
    p_pair = data.frame()
    p_glob = list()

    #Calculate a p-value for every loopnum
    for(simnum in unique(simul_db_temp0$n_sim)) {
      simul_db_temp = simul_db_temp0[simul_db_temp0$n_sim == simnum,] #filter for loopnum

      #Logrank tests
      #Global
      if("logrank" %in% global_test){
        p_glob[["N/Ap"]][["logrank"]][simnum] = survival::survdiff(survival::Surv(TTE, Status) ~ Trt.ID, simul_db_temp)$pvalue
      }

      #Pairwise
      for(pairwise_corr_id0 in pairwise_corr[pairwise_corr %in% c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none")]){
        if("logrank" %in% pairwise_test) {
          pair_lr_res = survminer::pairwise_survdiff(survival::Surv(TTE, Status) ~ Trt.ID,
                                                     simul_db_temp, p.adjust.method = pairwise_corr_id0)
          temp_pair2 = data.frame(as.table(pair_lr_res$p.value))
          temp_pair2 = temp_pair2[-which(is.na(temp_pair2$Freq)),]

          p_pair = rbind(p_pair, data.frame(pair = interaction(temp_pair2$Var2, temp_pair2$Var1, sep = " - "),
                                            pvalues = temp_pair2$Freq,
                                            model = "N/Ap",
                                            pairwise_test = "logrank",
                                            corr = pairwise_corr_id0))
        }
      }

      #Model fits
      if("coxph_glm" %in% model){
        coxph_glm = survival::coxph(survival::Surv(TTE, Status) ~ Trt.ID, simul_db_temp)
        coxph_glm_sum = summary(coxph_glm)
      }
      if("coxph_glmm" %in% model){coxph_glmm <- coxme::coxme(survival::Surv(TTE, Status) ~ Trt.ID + (1|Tank.ID), simul_db_temp)}

      #Repeat for every model
      for(mod_id in model){ #for every model...

        #Repeat for every pairwise comparison correction setting
        for(pairwise_corr_id in pairwise_corr) { #for every pairwise comparison setting..
          if("EMM" %in% pairwise_test) {
            temp_pair = data.frame(emmeans::emmeans(mget(mod_id, envir = environment())[[1]],
                                                    pairwise ~ Trt.ID, adjust = pairwise_corr_id)$contrasts)

            p_pair = rbind(p_pair, data.frame(pair = temp_pair$contrast,
                                              pvalues = temp_pair$p.value,
                                              model = mod_id,
                                              pairwise_test = "EMM",
                                              corr = pairwise_corr_id))
          }
        }

        #Repeat for every global_test setting
        for(glob_id in global_test){
          if(glob_id == "wald"){p_glob[[mod_id]][[glob_id]][simnum] <- emmeans::joint_tests(mget(mod_id,
                                                                                                 envir = environment())[[1]])$p.value}
          if(glob_id == "score"){
            if(mod_id == "coxph_glm"){p_glob[[mod_id]][[glob_id]][simnum] <- coxph_glm_sum$waldtest["pvalue"]}
            if(mod_id == "coxph_glmm"){p_glob[[mod_id]][[glob_id]][simnum] <- NA} #Method not available/allowed
          }

          if(glob_id == "LRT"){
            if(mod_id == "coxph_glm"){p_glob[[mod_id]][[glob_id]][simnum] <- coxph_glm_sum$logtest["pvalue"]}
            if(mod_id == "coxph_glmm"){
              p_glob[[mod_id]][[glob_id]][simnum] =
                anova(coxph_glmm, coxme::coxme(survival::Surv(TTE, Status) ~ 1 + (1|Tank.ID), simul_db_temp))$`P(>|Chi|)`[2]
            }
          }
        }
      }

      #Print progress
      cat("\rCalculated p-values for", prog <- prog + 1, "of",
          max(simul_db$list_element_num) * max(simul_db_temp0$n_sim), "sample sets")
    } #Close loop for simnum

    #Create power tables from p-values for each ele_num
    #For global test pvalues
    if(length(p_glob) > 0){
      p_glob_unlist = stack(unlist(p_glob))
      p_glob_unlist$ind = gsub(pattern = "[0-9]", x = p_glob_unlist$ind, replacement = "")
      p_glob_db = data.frame(tidyr::separate(data = p_glob_unlist, col = "ind",
                                             into = c("model", "global_test"), sep = "\\."))
      power_glob_temp = data.frame(p_glob_db %>%
                                     dplyr::group_by(model, global_test) %>%
                                     dplyr::summarise(percent_signif = 100 * sum(values < 0.05)/length(values),
                                                      datasets_n = length(values), .groups = "drop"))
      power_glob_temp$percent_signif_se = sqrt(power_glob_temp$percent_signif *
                                                 (100-power_glob_temp$percent_signif) /
                                                 (power_glob_temp$datasets_n))
      power_glob_temp = power_glob_temp[, c("model", "global_test", "percent_signif", "percent_signif_se", "datasets_n")]
      power_glob_temp$element_num = ele_num
      power_glob = rbind(power_glob, power_glob_temp)
    }

    #For pairwise test pvalues
    if(length(p_pair) > 0){
      power_pair_temp = data.frame(p_pair %>%
                                     dplyr::group_by(pair, model, pairwise_test, corr) %>%
                                     dplyr::summarise(percent_signif = 100 * sum(pvalues < 0.05)/length(pvalues),
                                                      datasets_n = length(pvalues), .groups = "drop"))
      power_pair_temp$percent_signif_se = sqrt(power_pair_temp$percent_signif *
                                                 (100-power_pair_temp$percent_signif) /
                                                 (power_pair_temp$datasets_n))
      power_pair_temp = power_pair_temp[, c("pair", "model", "pairwise_test", "corr", "percent_signif",
                                            "percent_signif_se", "datasets_n")]
      power_pair_temp$element_num = ele_num
      power_pair = rbind(power_pair, power_pair_temp)
    }
  } #Close loop for ele_num

  #Outermost steps
  #Plot #1 (global test)
  if(length(p_glob) > 0){
    mod_col = c("N/Ap" = "#F8766D", "coxph_glm" = "#00BA38", "coxph_glmm" = "#00BFC4")
    power_glob$model = factor(power_glob$model, levels = c("N/Ap", "coxph_glm", "coxph_glmm"))
    power_glob$global_test = factor(power_glob$global_test, levels = c("logrank", "wald", "score", "LRT"))
    test_shapes = c(15:18)
    names(test_shapes) = c("logrank", "wald", "score", "LRT")

    glob_plot = ggplot(data = na.omit(power_glob), aes(x = as.numeric(element_num), y = percent_signif/100,
                                                       colour = model, group = interaction(model, global_test))) +
      geom_errorbar(aes(ymin = (percent_signif - percent_signif_se)/100,
                        ymax = (percent_signif + percent_signif_se)/100),
                    position = position_dodge(width = 0.12), width = 0.1) +
      geom_point(aes(shape = global_test), position = position_dodge(width = 0.12)) +
      scale_y_continuous(labels = scales::percent, breaks = seq(0, 1, 0.1), limits = c(0, 1),
                         name = "% of significant results (p<0.05)") +
      scale_x_continuous(breaks = seq(1, max(power_glob$element_num), 1),
                         name = ifelse(is.null(xlab), "List Element #", xlab),
                         labels = if(is.null(xnames)){waiver()}
                         else{stringr::str_wrap(xnames, width = round(24/max(power_pair$element_num)))}) +
      labs(color = "Model", shape = "Test", title = "Global Test of Significance") +
      theme(plot.title = element_text(hjust = 0)) +
      guides(linetype = "none",
             shape = guide_legend(order = 2),
             colour = guide_legend(order = 1)) +
      scale_color_manual(values = mod_col) +
      scale_shape_manual(values = test_shapes)

    if(plot_lines == TRUE) {glob_plot <- glob_plot + geom_line(aes(linetype = global_test), position = position_dodge(width = 0.12))}

  } else {glob_plot <- NULL}

  #Plot #2 (pairwise test)
  if(length(p_pair) > 0){
    power_pair$pair = gsub(" - ", " vs. ", power_pair$pair)
    u_pairs = length(unique(power_pair$pair))
    n_col = ceiling(u_pairs/2)
    test_and_corr_combos = rev(levels(interaction(c("logrank", "EMM"), pairwise_corr_options, sep = " & ")))[-1]
    power_pair$test_and_corr = interaction(power_pair$pairwise_test, power_pair$corr, sep = " & ")
    power_pair$test_and_corr = factor(power_pair$test_and_corr, levels = test_and_corr_combos)
    power_pair$model = factor(power_pair$model, levels = c("N/Ap", "coxph_glm", "coxph_glmm", "coxph_gee"))
    test_and_corr_shapes = c(3, rep(c(15:18, 4, 7, 25), each = 2))
    names(test_and_corr_shapes) = test_and_corr_combos

    pair_plot = ggplot(data = power_pair, aes(x = as.numeric(element_num), y = percent_signif/100, colour = model,
                                              group = interaction(model, test_and_corr))) +
      facet_wrap(~pair, ncol = n_col) +
      geom_errorbar(aes(ymin = (percent_signif - percent_signif_se)/100,
                        ymax = (percent_signif + percent_signif_se)/100),
                    position = position_dodge(width = 0.30), width = 0.1) +
      geom_point(aes(shape = test_and_corr), position = position_dodge(width = 0.30)) +
      scale_y_continuous(labels = scales::percent, breaks = seq(0, 1, 0.1), limits = c(0, 1),
                         name = "% of significant results (p<0.05)") +
      scale_x_continuous(breaks = seq(1, max(power_pair$element_num), 1),
                         name = ifelse(is.null(xlab), "List Element #", xlab),
                         labels = if(is.null(xnames)){waiver()}
                         else{stringr::str_wrap(xnames, width = round(48/(max(power_pair$element_num) * n_col)))}) +
      labs(color = "Model", shape = "Test & Correction", title = "Pairwise Test of Significance") +
      theme(plot.title = element_text(hjust = 0)) +
      guides(linetype = "none",
             shape = guide_legend(order = 2),
             colour = guide_legend(order = 1)) +
      scale_color_manual(values = mod_col) +
      scale_shape_manual(values = test_and_corr_shapes)


    if(plot_lines == TRUE) {pair_plot <- pair_plot + geom_line(aes(linetype = test_and_corr), position = position_dodge(width = 0.30))}
  } else {pair_plot <- NULL}

  #Return output
  output = list()
  if(!is.null(global_test)){
    output[["power_global_db"]] = power_glob
    if(plot_out == TRUE & length(power_glob) > 0) {
      output[["power_global_plot"]] = glob_plot
      if(plot_save == TRUE) {
        ggsave(paste("Power_Global_Test_", Sys.Date(), ".tiff", sep =""),
               dpi = 900, width = 7, height = 5.5, plot = glob_plot)
      }
    }
  }
  if(!is.null(pairwise_test)){
    output[["power_pairwise_db"]] = power_pair[, -which((colnames(power_pair) == "test_and_corr"))]
    if(plot_out == TRUE & length(pair_plot) > 0) {
      output[["power_pairwise_plot"]] = pair_plot
      if(plot_save == TRUE) {
        ggsave(paste("Power_Pairwise_Test_", Sys.Date(), ".tiff", sep =""),
               dpi = 900, width = 1.5 + (2.75 * ceiling(u_pairs / n_col)),
               height = 2.75 * n_col, plot = pair_plot)
      }
    }
  }

  #Validation checks (print notes)
  ##For global tests
  if("coxph_glmm" %in% model & "score" %in% global_test){
    print("NOTE: No off-the-shelf function for conducting a Likelihood Ratio Test on 'coxph_glmm' models in R. No power value is returned for the global test using LRT on 'coxph_glmm' model.")
  }

  ##For pairwise tests
  if("logrank" %in% pairwise_test & "tukey" %in% pairwise_corr) {
    print("NOTE: Tukey pairwise correction is not available for log-rank tests. No power value is returned for such a combination of test and correction.")
  }

  if(is.null(model)){
    if("EMM" %in% pairwise_test){
      print("NOTE: No pairwise comparison of type 'EMM' was done since no model was specified.")
    }
    if(sum(global_test %in% c("wald", "score", "LRT")) > 0){
      print(paste("NOTE: No global_test of type", global_test, "was done since no model was specified."))
    }
  }

  if(is.null(pairwise_test)){
    print("NOTE: No pairwise test was done since pairwise_test was set to NULL.")
  }
  if(is.null(global_test)){
    print("NOTE: No global test was done since global_test was set to NULL.")
  }

  #Print time elapsed
  print(paste("Time elapsed:", substr(hms::as_hms(Sys.time() - time_start), 1, 8), "(hh:mm:ss)"))
  return(output)
}

```

```{r}
power.fisher <- function(p1, p2, n, alpha, alternative)
{
# p1 = 0.5
# p2 = 0.3
# n = 30
# alpha = 0.05
# alternative = "two.sided"
#   
  pr1 <- dbinom(0:n, n, p1, log = T)
  pr2 <- dbinom(0:n, n, p2, log = T)
  y1 <- rep(0:n, each = n + 1)
  y2 <- rep(0:n, times = n + 1)
  y <- cbind(y1, n - y1, y2, n - y2)
  pr <- exp(rep(pr1, each = n + 1) + rep(pr2, times = n + 1))
  res <- 0
  for (i in 1:length(pr))
  {
    pval <- fisher.test(matrix(y[i, ], 2, 2), alternative = alternative)$p.value
    res <- res + (pval <= alpha) * pr[i]
  }

  return(res)
}
```

```{r}
Surv_Simul = function(haz_db,
                      fish_num_per_tank = 100,
                      tank_num_per_trt = 4,
                      treatments_hr = c(1, 1, 1, 1),
                      logHR_sd_intertank = 0,
                      sampling_specs = NULL,
                      exp_design = "between-tank",
                      n_sim = 1,
                      prog_show = TRUE,
                      plot_out = TRUE,
                      pop_out = TRUE,
                      theme = "ggplot2",
                      plot_save = TRUE) {
  #Track time elapsed
  time_start = Sys.time()

  #Making sure input data has correct (lower case) column names
  colnames(haz_db) = tolower(colnames(haz_db))

  #Validation check
  if(length(levels(factor(haz_db$tr.id))) > 1) {stop("Please use only one Trt.ID in the supplied hazard dataframe.")}

  #Add blank for last time point in haz_db, for convenience on later calculations
  haz_db = rbind(haz_db, data.frame(trt.id = haz_db$trt.id[1], hazard = last(cumsum(haz_db$hazard)) * .Machine$double.eps * 10, 
                                    time = round(last(haz_db$time))))

  #Initialize objects to store second output type (across list elements and loops)
  output2 = list(surv_plots = list(), surv_simul_db = data.frame(), surv_pop_db = data.frame())
  list_var_check = c()

  #Validation Check(s)
  if(plot_out == TRUE) {
    if(logHR_sd_intertank > 0) {
      print("NOTE: You specified a tank effect/contribution to variation, but the power shown in the plot is based of the logrank test. This test assumes no such tank effects. Adding tank-variation tends to decrease power of the logrank when the treatment effect is strong-modest (see Examples in Surv_Simul()'s documentation). Despite the decrease, power of the logrank will still be greater than that of other statistical tests which considers tank variation (assuming the experimental design is 'between-tank' because this matters). At the cost of having the greater power, logrank suffers from a greater false positive rate (> 5%). To calculate power of other tests that account for tank variation (hence keeping FPR at ~5%), use the coxph_glmm model option in the function Surv_Power() from package safuncs.")
    }
  }

  #Finding the input variable (var_name) that is a list and store info in var_list
  #First we stop the function if we find more than 1 list
  var_names = c("fish_num_per_tank", "tank_num_per_trt", "treatments_hr", "logHR_sd_intertank", "sampling_specs")
  for (var_name_check in var_names) {
    if(is.list(get(var_name_check, envir = environment())) & !is.data.frame(get(var_name_check, envir = environment()))){
      list_var_check = c(list_var_check, var_name_check)
    }
  }
  if(length(list_var_check) > 1) {stop("You specified more than 1 argument/parameter as a list. Currently, this is not allowed.")}

  for (var_name in var_names) {
    ifelse(is.list(get(var_name, envir = environment()))
           & !is.data.frame(get(var_name, envir = environment())),
           list_var <- get(var_name, envir = environment()),
           list_var <- "empty")
    if(length(list_var) > 1) {
      break
    }
  }

  #Track progress
  prog = 0

  #Change var_name based on list_var elements
  for (ele_num in 1:length(list_var)) {

    #if you have list elements, assign and print. If not just jump straight to old code
    if(length(list_var) > 1) { #if you have list elements, assign and print, otherwise just go to old code.
      assign(var_name, list_var[[ele_num]]) #assign
    }

    #Old code below. Will only run once if there is no list (i.e. length(list_var) = 1)

    #Initialize objects to store loop results
    surv_samps = data.frame() #for plotting purposes
    cens_db = data.frame() #for plotting purposes
    pvalues = c() #for plotting purposes
    Surv_simul_outDB = data.frame() #for dataoutput

    #Simulate survival dataframe
    for(loopnum in 1:n_sim) {

      CDF_Yval = c()
      Trt.ID = c()
      Tank.ID = c()
      Tank_num2 = 0
      iTT = 0

      if(exp_design == "between-tank") { #simulation procedure for between-tanks experimental design

        for(Treatment_Term in treatments_hr) {
          iTT = iTT + 1

          for(Tank_num in 1:ifelse(length(tank_num_per_trt) > 1, tank_num_per_trt[iTT], tank_num_per_trt)) {
            Tank_num2 = Tank_num2 + 1

            #Random sampling
            Tank_eff = rnorm(n = 1, mean = 0, sd = logHR_sd_intertank)

            U = runif(n = ifelse(length(fish_num_per_tank) > 1, fish_num_per_tank[iTT], fish_num_per_tank), min = 0, max = 1)

            CDF_Yval_temp = -log(U) * exp(-(log(Treatment_Term) + Tank_eff))
            CDF_Yval = append(CDF_Yval, CDF_Yval_temp)

            Trt.ID = c(Trt.ID, rep(c("Control", LETTERS[1:(length(treatments_hr) - 1)])[iTT], length(CDF_Yval_temp)))
            Tank.ID = c(Tank.ID, rep(Tank_num2, length(CDF_Yval_temp)))
          }
        }

      }
      if(exp_design == "within-tank") { #simulation procedure for within-tank experimental design. Similar but with flipped Tank-Trt loops.

        for(Tank_num in 1:tank_num_per_trt) { #only 1 tank num can be specified for the within-tank design.
          Tank_num2 = Tank_num2 + 1

          #Tank effect
          Tank_eff = rnorm(n = 1, mean = 0, sd = logHR_sd_intertank)

          iTT = 0
          for(Treatment_Term in treatments_hr) {
            iTT = iTT + 1

            #Simulate fish numbers per treatment for each tank. Write down in description that it must be per treatment per tank.
            #Can be as vector for treatment specific numbers or can be a single value if the same across treatments.
            U = runif(n = ifelse(length(fish_num_per_tank) > 1, fish_num_per_tank[iTT], fish_num_per_tank), min = 0, max = 1)

            CDF_Yval_temp = -log(U) * exp(-(log(Treatment_Term) + Tank_eff))
            CDF_Yval = append(CDF_Yval, CDF_Yval_temp)

            Trt.ID = c(Trt.ID, rep(c("Control", LETTERS[1:(length(treatments_hr) - 1)])[iTT], length(CDF_Yval_temp)))
            Tank.ID = c(Tank.ID, rep(Tank_num2, length(CDF_Yval_temp)))
          }
        }
      }

      #Get Time to Event
      TTE = approx(x = cumsum(haz_db$hazard), y = haz_db$time, xout = CDF_Yval, method = "linear")$y
      TTE = round(TTE, digits = 0)

      #Turn NA (from out of bound CDF_Yval) to the last follow up time
      TTE = ifelse(is.na(TTE), max(haz_db$time), TTE)

      #Label Status (1 - dead, or 0 - survived) given TTE, and create survival dataframe
      Surv_simul_DB = data.frame(TTE = TTE,
                                 Status = ifelse(TTE == max(haz_db$time), 0, 1),
                                 Trt.ID = Trt.ID,
                                 Tank.ID = Tank.ID,
                                 n_sim = loopnum)

      #Transform TTE and Status (to 0) in certain rows due to sampling
      if(!is.null(sampling_specs)) {

        if(!"Trt.ID" %in% colnames(sampling_specs)) {
          Trt_levels = unique(Surv_simul_DB$Trt.ID)
          sampling_specs = data.frame(TTE = rep(sampling_specs$TTE, each = length(Trt_levels)),
                                      Amount = rep(sampling_specs$Amount, each = length(Trt_levels)),
                                      Trt.ID = rep(unique(Trt_levels), times = nrow(sampling_specs)))
        }

        #Put in Tank.ID and replicate accordingly
        sampling_specs2 = merge(sampling_specs, unique(Surv_simul_DB[, 3:4]))

        #Run through every row of sampling_specs and sample accordingly
        for(samp_row in 1:nrow(sampling_specs2)) {

          rows_samp_space = which(Surv_simul_DB$Trt.ID == sampling_specs2$Trt.ID[samp_row] &
                                    Surv_simul_DB$Tank.ID == sampling_specs2$Tank.ID[samp_row] &
                                    Surv_simul_DB$TTE > sampling_specs2$TTE[samp_row])

          #Catch over sampling situation and print message
          if(length(rows_samp_space) < sampling_specs2$Amount[samp_row]) {
            print(paste(sep = "", "In simulation set-", loopnum, " Trt.ID-", sampling_specs2$Trt.ID[samp_row], ", Tank.ID-",
                        sampling_specs2$Tank.ID[samp_row],
                        ", you requested more samples than the fish alive! All remaining (living) fish sampled."))

            #Modify sampling amount
            sampling_specs2$Amount[samp_row] = length(rows_samp_space)
          }

          #Select rows that were sampled
          rows_sel = sample(x = rows_samp_space,
                            size = sampling_specs2$Amount[samp_row],
                            replace = FALSE)

          #Change Status and Time for sampled individuals
          Surv_simul_DB$TTE[rows_sel] = sampling_specs2$TTE[samp_row]
          Surv_simul_DB$Status[rows_sel] = 0
        }
      }

      #Get p-value for plots
      pvalues = append(pvalues, survival::survdiff(survival::Surv(TTE, Status) ~ Trt.ID, Surv_simul_DB)$pvalue)

      #Simulated survival data to be provided as output
      if(length(list_var) > 1){Surv_simul_DB$list_element_num <- ele_num}

      Surv_simul_outDB = rbind(Surv_simul_outDB, Surv_simul_DB)

      #Transform simulated survival data for plotting purposes
      surv_obj = survival::survfit(survival::Surv(TTE, Status) ~ Trt.ID, data = Surv_simul_DB)
      if(length(levels(as.factor(Surv_simul_DB$Trt.ID))) > 1) {
        attributes(surv_obj$strata)$names <- levels(as.factor(Surv_simul_DB$Trt.ID))
      } else {
        surv_obj$strata = length(surv_obj$surv)
        attributes(surv_obj$strata)$names <- levels(as.factor(Surv_simul_DB$Trt.ID))
      }

      surv_samps_temp = data.frame(Trt.ID = summary(surv_obj)$strata,
                                   surv_prob = summary(surv_obj)$surv,
                                   time = summary(surv_obj)$time,
                                   type = paste("Sample set (n = ", n_sim, ")", sep = ""),
                                   n_sim = loopnum,
                                   alpha = 1 - (0.0001 ^ (1/n_sim)))
      if(length(list_var) > 1){surv_samps_temp$list_element_num <- ele_num}

      surv_samps_ends = data.frame(surv_samps_temp %>%
                                     dplyr::group_by(Trt.ID) %>%
                                     dplyr::reframe(surv_prob = c(1, min(surv_prob)),
                                                    time = c(floor(min(haz_db$time)), ceiling(max(haz_db$time))),
                                                    n_sim = loopnum,
                                                    alpha = 1 - (0.0001 ^ (1/n_sim))))
      surv_samps_ends$type = paste("Sample set (n = ", n_sim, ")", sep = "")
      if(length(list_var) > 1){surv_samps_ends$list_element_num <- ele_num}

      surv_samps = rbind(surv_samps, surv_samps_temp, surv_samps_ends)

      if(!is.null(sampling_specs)){
        #Get survival probability at mid censoring
        cens_db_temp  = data.frame(Trt.ID = summary(surv_obj, time = sampling_specs$TTE)$strata,
                                   surv_prob = summary(surv_obj, time = sampling_specs$TTE)$surv,
                                   time = summary(surv_obj, time = sampling_specs$TTE)$time,
                                   n_sim = loopnum,
                                   type = as.factor(paste("Sample set (n = ", n_sim, ")", sep = "")))
        cens_db = rbind(cens_db, cens_db_temp)
      }

      #Print progress
      if(prog_show != FALSE) {cat("\rSimulated", prog <- prog + 1, "of", n_sim * length(list_var), "sample sets")}
    } #close loopnum

    #Get "population" survival dataset by exponentiating the negative cumulative hazard
    pop_haz_db = data.frame(approx(x = haz_db$time, y = haz_db$hazard, xout = seq(min(haz_db$time), max(haz_db$time), 0.1), method = "linear"))
    colnames(pop_haz_db) = c("time", "hazard")

    #For use with old surv_prob method (revived)
    surv_pop = data.frame(Trt.ID = as.factor(rep(c("Control", LETTERS[1:(length(treatments_hr) - 1)]), each = length(haz_db$hazard))),
                          #cumhaz_prob = as.vector(apply((haz_db$hazard) %*% t(treatments_hr), 2, cumsum)),
                          surv_prob = exp(-as.vector(apply(haz_db$hazard %*% t(treatments_hr), 2, cumsum))),
                          time = rep(haz_db$time, times = length(treatments_hr)),
                          type = "Population / truth",
                          n_sim = 1,
                          alpha = 1)
    if(length(list_var) > 1){surv_pop$list_element_num <- ele_num}

    #To the end of creating survival plots
    surv_comb = rbind(surv_samps, surv_pop)
    surv_comb$type = factor(surv_comb$type, levels = c(paste("Sample set (n = ", n_sim, ")", sep = ""), "Population / truth"))
    surv_comb$Trt.ID = factor(surv_comb$Trt.ID, levels = rep(c("Control", LETTERS[1:(length(treatments_hr) - 1)])))

    #Get end_sr for population plots and sample plots
    end_db = data.frame(surv_comb %>%
                          dplyr::group_by(type, Trt.ID, n_sim) %>%
                          dplyr::summarise(surv_prob = min(surv_prob), time = max(TTE), .groups = "drop") %>%
                          dplyr::group_by(type, Trt.ID) %>%
                          dplyr::summarise(surv_prob = mean(surv_prob), time = max(time), .groups = "drop"))

    #Get % significance (i.e. power) for plotting
    perc_sf = paste(round(100 * sum(pvalues < 0.05) / length(pvalues), digits = 0), "%", sep = "")

    #Ggplot
    surv_plots = ggplot(data = surv_comb, aes(x = time, y = surv_prob, colour = Trt.ID, group = interaction(n_sim, Trt.ID))) +
      facet_wrap(~ type) +
      geom_step(aes(alpha = alpha)) +
      scale_y_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1), labels = scales::percent) +
      scale_x_continuous(breaks = seq(0, max(surv_pop$time), max(round(max(surv_pop$time) / 12), 1))) +
      ylab("Survival Probability (%)") +
      xlab("Time to Event") +
      scale_alpha(range = c(min(surv_comb$alpha), 1)) +
      guides(alpha = "none") +
      coord_cartesian(clip = "off", xlim = c(min(haz_db$time), max(haz_db$time) - 0.5)) +
      theme(plot.margin = margin(5.5, 20, 5.5, 5.5))

    if(n_sim == 1) {
      surv_plots = surv_plots +
        geom_text(data = end_db, aes(x = time, y = surv_prob, label = round(surv_prob * 100, digits = 0)),
                  vjust = -0.3, hjust = 0.8, show.legend = FALSE, size = 3.3) +
        annotation_custom(grob = grid::textGrob(paste(c(paste("The sample has a", sep = ""),
                                                        paste("p-value = ", signif(pvalues, digits = 2), sep = ""),
                                                        "(global test of Trt.)"), collapse = "\n"),
                                                x = grid::unit(1.05, "npc"),
                                                y = grid::unit(0.08, "npc"),
                                                hjust = 0,
                                                gp = grid::gpar(fontsize = 9)))
    } else {
      surv_plots = surv_plots +
        geom_text(data = end_db[end_db$type == "Population / truth",],
                  aes(x = time, y = surv_prob, label = round(surv_prob * 100, digits = 0)),
                  vjust = -0.3, hjust = 0.8, show.legend = FALSE, size = 3.3) +
        annotation_custom(grob = grid::textGrob(paste(c(paste(perc_sf, " of the sample", sep = ""),
                                                        paste("sets (n) has p<0.05", sep = ""),
                                                        "(global test of Trt.)"), collapse = "\n"),
                                                x = grid::unit(1.03, "npc"),
                                                y = grid::unit(0.08, "npc"),
                                                hjust = 0,
                                                gp = grid::gpar(fontsize = 9)))
    }

    #Add censoring points
    if(!is.null(sampling_specs)) {
      merged_db = merge(sampling_specs2, Surv_simul_DB)
      merged_db = merged_db[merged_db$Status == 0, ]
      cens_db = cens_db[interaction(cens_db$Trt.ID, cens_db$time) %in% interaction(merged_db$Trt.ID, merged_db$TTE),]
      surv_plots = surv_plots +
        geom_point(data = cens_db, aes(x = time, y = surv_prob, colour = Trt.ID), shape = 3, size = 0.7, stroke = 1)
    }

    #Plot theme
    if(theme == "prism") {surv_plots = surv_plots + ggprism::theme_prism()}

    #Plot title
    if(length(list_var > 1)) {

      surv_plots = surv_plots + labs(title = paste("List Element", ele_num))
    }

    #Save plot
    if(plot_save == TRUE){
      ggsave(paste("Surv_Simul_Plot",
                   ifelse(length(list_var) == 1, "_", paste("_Element", ele_num, "_", sep ="")),
                   Sys.Date(), ".tiff", sep = ""), dpi = 900, width = 7, height = 4, plot = surv_plots)
    }

    #remove columns "alpha", "type", and "n_sim" from data output
    surv_pop = surv_pop[, -c(4:6)]
    colnames(surv_pop) = c("Trt.ID", "surv_prob", "TTE")

    #Return R output if list_var length = 1 (i.e. no list)
    if(length(list_var) == 1) {
      if(plot_out == FALSE & pop_out == FALSE) {
        #Print time elapsed
        print(paste("Time elapsed:", substr(hms::as_hms(Sys.time() - time_start), 1, 8), "(hh:mm:ss)"))
        return(surv_simul_db = Surv_simul_outDB)

      } else {

        output = list(surv_simul_db = Surv_simul_outDB)

        if(pop_out == TRUE) {output$surv_pop_db <- surv_pop}
        if(plot_out == TRUE) {output$surv_plots <- surv_plots}

        #Print time elapsed
        print(paste("Time elapsed:", substr(hms::as_hms(Sys.time() - time_start), 1, 8), "(hh:mm:ss)"))
        return(output)
      }
    }

    if(length(list_var) > 1) {

      #Store 2nd output if list_var length >1
      output2$surv_plots[[ele_num]] = surv_plots
      output2$surv_simul_db = rbind(output2$surv_simul_db, Surv_simul_outDB)
      output2$surv_pop_db = rbind(output2$surv_pop_db, surv_pop)
    }

    #Old code (non-lists stuff) ends here

  } #This closes the loop that deals with lists

  if(length(list_var) > 1){

    if(plot_out == FALSE) {
      output2$surv_plots = NULL
    }

    if(pop_out == FALSE) {
      output2$surv_pop_db = NULL
    }

    #Print time elapsed
    print(paste("Time elapsed:", substr(hms::as_hms(Sys.time() - time_start), 1, 8), "(hh:mm:ss)"))
    return(output2)
  }
}
```

```{r}
simul_db_ex = safuncs::Surv_Simul(haz_db = haz_db_ex,
          fish_num_per_tank = list(20, 60, 100),
          tank_num_per_trt = 3,
            treatments_hr = c(1, 0.5),
            n_sim = 30,
          pop_out = TRUE,
          plot_out = TRUE)
```



```{r}
simul_db_ex
```

Creating Surv_Power()
```{r}
simul_db = simul_db_ex
                      global_test = "logrank"
                      model = NULL
                      pairwise_test = "logrank"
                      pairwise_corr = "none"
                      prog_show = TRUE
                      plot_out = TRUE
                      plot_lines = FALSE
                      xlab = "List Element #"
                      xnames = NULL
                      plot_save = TRUE

  #Track time elapsed
  time_start = Sys.time()

  #Convert NULL pairwise_corr into "none"
  if(is.null(pairwise_corr)){pairwise_corr <- "none"}

  #Standardize simul_db as dataframe
  if(!is.data.frame(simul_db)){simul_db = data.frame(simul_db$simul_surv_db)}

  #Add a value of 1 for column list_element_num in case no value is present in simul_db
  if(!"list_element_num" %in% colnames(simul_db)){simul_db$list_element_num <- 1}

  #Validation checks (stops)
  if(sum(!global_test %in% c("logrank", "wald", "score", "LRT")) > 0) {
    stop(paste("The", global_test[!global_test %in% c("logrank", "wald", "score", "LRT")][1], "global test method is not in the list supported by Surv_Power(). Select any amount from 'logrank', 'wald', 'score', and/or 'LRT'. For no global test to be done, select NULL. "))
  }

  if(sum(!model %in% c("coxph_glm", "coxph_glmm")) > 0) {
    stop(paste("The", model[!model %in% c("coxph_glm", "coxph_glmm")][1], "model is currently not in the list supported by Surv_Power(). Select any amount from 'coxph_glm' and/or 'coxph_glmm'. For no model to be fitted, select NULL."))
  }

  if(sum(!pairwise_test %in% c("logrank", "EMM")) > 0) {
    stop(paste("The", pairwise_test[!pairwise_test %in% c("logrank", "EMM")][1], "pairwise test method is not in the list supported by Surv_Power(). Select any amount from 'logrank' and/or 'EMM'. For no pairwise test to be done, select NULL."))
  }

  pairwise_corr_options = c("tukey", "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "none")
  if(sum(!pairwise_corr %in% pairwise_corr_options) > 0) {
    stop(paste("The", pairwise_corr[!pairwise_corr %in% pairwise_corr_options][1], "pairwise correction method is not in the list supported by Surv_Power(). Select any amount from 'tukey', 'holm', 'hochberg', 'hommel', 'bonferroni', 'BH', 'BY', and/or 'none'."))
  }

  #Initialize objects to store values
  power_glob = data.frame()
  power_pair = data.frame()
  prog = 0

  #Subset data by list_element_num. Loop through each.
  for(ele_num in unique(simul_db$list_element_num)) {
    simul_db_temp0 = simul_db[simul_db$list_element_num == ele_num,] #filter for ele_num

    #Clear stored p_values for every ele_num
    p_pair = data.frame()
    p_glob = list()

    #Calculate a p-value for every loopnum
    for(simnum in unique(simul_db_temp0$n_sim)) {
      simul_db_temp = simul_db_temp0[simul_db_temp0$n_sim == simnum,] #filter for loopnum

      #Logrank tests
      #Global
      if("logrank" %in% global_test){
        p_glob[["N/Ap"]][["logrank"]][simnum] = survival::survdiff(survival::Surv(TTE, Status) ~ Trt.ID, simul_db_temp)$pvalue
      }

      #Pairwise
      for(pairwise_corr_id0 in pairwise_corr[pairwise_corr %in% c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none")]){
        if("logrank" %in% pairwise_test) {
          pair_lr_res = survminer::pairwise_survdiff(survival::Surv(TTE, Status) ~ Trt.ID,
                                                     simul_db_temp, p.adjust.method = pairwise_corr_id0)
          temp_pair2 = na.omit(data.frame(as.table(pair_lr_res$p.value)))

          p_pair = rbind(p_pair, data.frame(pair = interaction(temp_pair2$Var2, temp_pair2$Var1, sep = " - "),
                                            pvalues = temp_pair2$Freq,
                                            model = "N/Ap",
                                            pairwise_test = "logrank",
                                            corr = pairwise_corr_id0))
        }
      }

      #Model fits
      if("coxph_glm" %in% model){
        coxph_glm = survival::coxph(survival::Surv(TTE, Status) ~ Trt.ID, simul_db_temp)
        coxph_glm_sum = summary(coxph_glm)
      }
      if("coxph_glmm" %in% model){coxph_glmm <- coxme::coxme(survival::Surv(TTE, Status) ~ Trt.ID + (1|Tank.ID), simul_db_temp)}

      #Repeat for every model
      for(mod_id in model){ #for every model...

        #Repeat for every pairwise comparison correction setting
        for(pairwise_corr_id in pairwise_corr) { #for every pairwise comparison setting..
          if("EMM" %in% pairwise_test) {
            temp_pair = data.frame(emmeans::emmeans(mget(mod_id, envir = environment())[[1]],
                                                    pairwise ~ Trt.ID, adjust = pairwise_corr_id)$contrasts)

            p_pair = rbind(p_pair, data.frame(pair = temp_pair$contrast,
                                              pvalues = temp_pair$p.value,
                                              model = mod_id,
                                              pairwise_test = "EMM",
                                              corr = pairwise_corr_id))
          }
        }

        #Repeat for every global_test setting
        for(glob_id in global_test){
          if(glob_id == "wald"){p_glob[[mod_id]][[glob_id]][simnum] <- emmeans::joint_tests(mget(mod_id,
                                                                                                 envir = environment())[[1]])$p.value}
          if(glob_id == "score"){
            if(mod_id == "coxph_glm"){p_glob[[mod_id]][[glob_id]][simnum] <- coxph_glm_sum$waldtest["pvalue"]}
            if(mod_id == "coxph_glmm"){p_glob[[mod_id]][[glob_id]][simnum] <- NA} #Method not available/allowed
          }

          if(glob_id == "LRT"){
            if(mod_id == "coxph_glm"){p_glob[[mod_id]][[glob_id]][simnum] <- coxph_glm_sum$logtest["pvalue"]}
            if(mod_id == "coxph_glmm"){
              p_glob[[mod_id]][[glob_id]][simnum] =
                anova(coxph_glmm, coxme::coxme(survival::Surv(TTE, Status) ~ 1 + (1|Tank.ID), simul_db_temp))$`P(>|Chi|)`[2]
            }
          }
        }
      }

      #Print progress
      if(prog_show == TRUE) {cat("\rCalculated p-values for", prog <- prog + 1, "of",
                                  max(simul_db$list_element_num) * max(simul_db_temp0$n_sim), "sample sets")}
    } #Close loop for simnum

    #Create power tables from p-values for each ele_num
    #For global test pvalues
    if(length(p_glob) > 0){
      p_glob_unlist = stack(unlist(p_glob))
      p_glob_unlist$ind = gsub(pattern = "[0-9]", x = p_glob_unlist$ind, replacement = "")
      p_glob_db = data.frame(tidyr::separate(data = p_glob_unlist, col = "ind",
                                             into = c("model", "global_test"), sep = "\\."))
      power_glob_temp = data.frame(p_glob_db %>%
                                     dplyr::group_by(model, global_test) %>%
                                     dplyr::summarise(percent_signif = 100 * sum(values < 0.05)/length(values),
                                                      datasets_n = length(values), .groups = "drop"))
      power_glob_temp$percent_signif_se = sqrt(power_glob_temp$percent_signif *
                                                 (100-power_glob_temp$percent_signif) /
                                                 (power_glob_temp$datasets_n))
      power_glob_temp = power_glob_temp[, c("model", "global_test", "percent_signif", "percent_signif_se", "datasets_n")]
      power_glob_temp$element_num = ele_num
      power_glob = rbind(power_glob, power_glob_temp)
    }

    #For pairwise test pvalues
    if(length(p_pair) > 0){
      power_pair_temp = data.frame(p_pair %>%
                                     dplyr::group_by(pair, model, pairwise_test, corr) %>%
                                     dplyr::summarise(percent_signif = 100 * sum(pvalues < 0.05)/length(pvalues),
                                                      datasets_n = length(pvalues), .groups = "drop"))
      power_pair_temp$percent_signif_se = sqrt(power_pair_temp$percent_signif *
                                                 (100-power_pair_temp$percent_signif) /
                                                 (power_pair_temp$datasets_n))
      power_pair_temp = power_pair_temp[, c("pair", "model", "pairwise_test", "corr", "percent_signif",
                                            "percent_signif_se", "datasets_n")]
      power_pair_temp$element_num = ele_num
      power_pair = rbind(power_pair, power_pair_temp)
    }
  } #Close loop for ele_num

  #Outermost steps
  #Plot #1 (global test)
  if(length(p_glob) > 0){
    mod_col = c("N/Ap" = "#F8766D", "coxph_glm" = "#00BA38", "coxph_glmm" = "#00BFC4")
    power_glob$model = factor(power_glob$model, levels = c("N/Ap", "coxph_glm", "coxph_glmm"))
    power_glob$global_test = factor(power_glob$global_test, levels = c("logrank", "wald", "score", "LRT"))
    test_shapes = c(15:18)
    names(test_shapes) = c("logrank", "wald", "score", "LRT")

    glob_plot = ggplot(data = na.omit(power_glob), aes(x = as.numeric(element_num), y = percent_signif/100,
                                                       colour = model, group = interaction(model, global_test))) +
      geom_errorbar(aes(ymin = (percent_signif - percent_signif_se)/100,
                        ymax = (percent_signif + percent_signif_se)/100),
                    position = position_dodge(width = 0.12), width = 0.1) +
      geom_point(aes(shape = global_test), position = position_dodge(width = 0.12)) +
      scale_y_continuous(labels = scales::percent, breaks = seq(0, 1, 0.1), limits = c(0, 1),
                         name = "% of significant results (p<0.05)") +
      scale_x_continuous(breaks = seq(1, max(power_glob$element_num), 1),
                         name = ifelse(is.null(xlab), "List Element #", xlab),
                         labels = if(is.null(xnames)){waiver()}
                         else{stringr::str_wrap(xnames, width = round(24/max(power_pair$element_num)))}) +
      labs(color = "Model", shape = "Test", title = "Global Test of Significance") +
      theme(plot.title = element_text(hjust = 0)) +
      guides(linetype = "none",
             shape = guide_legend(order = 2),
             colour = guide_legend(order = 1)) +
      scale_color_manual(values = mod_col) +
      scale_shape_manual(values = test_shapes)

    if(plot_lines == TRUE) {glob_plot <- glob_plot + geom_line(aes(linetype = global_test), position = position_dodge(width = 0.12))}

  } else {glob_plot <- NULL}

  #Plot #2 (pairwise test)
  if(length(p_pair) > 0){
    power_pair$pair = gsub(" - ", " vs. ", power_pair$pair)
    u_pairs = length(unique(power_pair$pair))
    n_col = ceiling(u_pairs/2)
    test_and_corr_combos = rev(levels(interaction(c("logrank", "EMM"), pairwise_corr_options, sep = " & ")))[-1]
    power_pair$test_and_corr = interaction(power_pair$pairwise_test, power_pair$corr, sep = " & ")
    power_pair$test_and_corr = factor(power_pair$test_and_corr, levels = test_and_corr_combos)
    power_pair$model = factor(power_pair$model, levels = c("N/Ap", "coxph_glm", "coxph_glmm", "coxph_gee"))
    test_and_corr_shapes = c(3, rep(c(15:18, 4, 7, 25), each = 2))
    names(test_and_corr_shapes) = test_and_corr_combos

    pair_plot = ggplot(data = power_pair, aes(x = as.numeric(element_num), y = percent_signif/100, colour = model,
                                              group = interaction(model, test_and_corr))) +
      facet_wrap(~pair, ncol = n_col) +
      geom_errorbar(aes(ymin = (percent_signif - percent_signif_se)/100,
                        ymax = (percent_signif + percent_signif_se)/100),
                    position = position_dodge(width = 0.30), width = 0.1) +
      geom_point(aes(shape = test_and_corr), position = position_dodge(width = 0.30)) +
      scale_y_continuous(labels = scales::percent, breaks = seq(0, 1, 0.1), limits = c(0, 1),
                         name = "% of significant results (p<0.05)") +
      scale_x_continuous(breaks = seq(1, max(power_pair$element_num), 1),
                         name = ifelse(is.null(xlab), "List Element #", xlab),
                         labels = if(is.null(xnames)){waiver()}
                         else{stringr::str_wrap(xnames, width = round(48/(max(power_pair$element_num) * n_col)))}) +
      labs(color = "Model", shape = "Test & Correction", title = "Pairwise Test of Significance") +
      theme(plot.title = element_text(hjust = 0)) +
      guides(linetype = "none",
             shape = guide_legend(order = 2),
             colour = guide_legend(order = 1)) +
      scale_color_manual(values = mod_col) +
      scale_shape_manual(values = test_and_corr_shapes)


    if(plot_lines == TRUE) {pair_plot <- pair_plot + geom_line(aes(linetype = test_and_corr), position = position_dodge(width = 0.30))}
  } else {pair_plot <- NULL}

  #Return output
  output = list()
  if(!is.null(global_test)){
    output[["power_global_db"]] = power_glob
    if(plot_out == TRUE & length(power_glob) > 0) {
      output[["power_global_plot"]] = glob_plot
      if(plot_save == TRUE) {
        ggsave(paste("Power_Global_Test_", Sys.Date(), ".tiff", sep =""),
               dpi = 900, width = 7, height = 5.5, plot = glob_plot)
      }
    }
  }
  if(!is.null(pairwise_test)){
    output[["power_pairwise_db"]] = power_pair[, -which((colnames(power_pair) == "test_and_corr"))]
    if(plot_out == TRUE & length(pair_plot) > 0) {
      output[["power_pairwise_plot"]] = pair_plot
      if(plot_save == TRUE) {
        ggsave(paste("Power_Pairwise_Test_", Sys.Date(), ".tiff", sep =""),
               dpi = 900, width = 1.5 + (2.75 * ceiling(u_pairs / n_col)),
               height = 2.75 * n_col, plot = pair_plot)
      }
    }
  }

  #Validation checks (print notes)
  ##For global tests
  if("coxph_glmm" %in% model & "score" %in% global_test){
    print("NOTE: No off-the-shelf function for conducting a Likelihood Ratio Test on 'coxph_glmm' models in R. No power value is returned for the global test using LRT on 'coxph_glmm' model.")
  }

  ##For pairwise tests
  if("logrank" %in% pairwise_test & "tukey" %in% pairwise_corr) {
    print("NOTE: Tukey pairwise correction is not available for log-rank tests. No power value is returned for such a combination of test and correction.")
  }

  if(is.null(model)){
    if("EMM" %in% pairwise_test){
      print("NOTE: No pairwise comparison of type 'EMM' was done since no model was specified.")
    }
    if(sum(global_test %in% c("wald", "score", "LRT")) > 0){
      print(paste("NOTE: No global_test of type", global_test, "was done since no model was specified."))
    }
  }

  if(is.null(pairwise_test)){
    print("NOTE: No pairwise test was done since pairwise_test was set to NULL.")
  }
  if(is.null(global_test)){
    print("NOTE: No global test was done since global_test was set to NULL.")
  }

  #Print time elapsed
  print(paste("Time elapsed:", substr(hms::as_hms(Sys.time() - time_start), 1, 8), "(hh:mm:ss)"))
```


Surv_Power()
```{r}
z = Surv_Power(simul_db = simul_db_ex,
           model = c("coxph_glmm")           , #selection(s) from c("coxph_glm", "coxph_glmm", NULL). Defaults to NULL 
           global_test = c("logrank", "wald"), #selection(s) c("wald", "score", "LRT", "logrank")
           pairwise_test = c("logrank", "EMM"), #selection(s) c("EMM" or "logrank")
           pairwise_corr = c("none"), #selection of c("tukey", "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "none").
           plot_out = TRUE,
           plot_lines = TRUE,
           xlab = NULL,
           xnames = NULL,
           plot_save = FALSE)
```


Surv_Gen()
```{r}
mort_db = mort_db_ex
starting_fish_count = 100
last_tte = 54
tank_without_mort = NULL
trt_without_mort = NULL
output = "prism"

  #Count the number of rows in mort_db, for each combination of treatment and tank ID
  DB_Mort_Gensum = data.frame(mort_db %>%
                                dplyr::group_by(Trt.ID, Tank.ID) %>%
                                dplyr::summarise(Num_dead = dplyr::n()))

  #Include tanks without morts in the count database
  if(!is.null(tank_without_mort) && !is.null(trt_without_mort)) {
    WM_DB = data.frame(Trt.ID = trt_without_mort,
                       Tank.ID = tank_without_mort,
                       Num_dead = 0)
    DB_Mort_Gensum = rbind(DB_Mort_Gensum, WM_DB)
  }

  #Use tank-specific starting fish count if information provided
  if(is.data.frame(starting_fish_count)) {
    DB_Mort_Gensum = base::merge(DB_Mort_Gensum, starting_fish_count, all.y = TRUE)
    DB_Mort_Gensum$Num_dead[is.na(DB_Mort_Gensum$Num_dead)] = 0
    DB_Mort_Gensum$Num_alive = DB_Mort_Gensum$starting_fish_count - DB_Mort_Gensum$Num_dead
    DB_Mort_Gensum = DB_Mort_Gensum[, -3]
  } else {DB_Mort_Gensum$Num_alive = starting_fish_count - DB_Mort_Gensum$Num_dead}

  #Generate rows of data representing survivors
  DB_Mort_Genalive = data.frame(lapply(DB_Mort_Gensum, rep, DB_Mort_Gensum$Num_alive))
  DB_Mort_Genalive$Status = 0
  DB_Mort_Genalive$TTE = last_tte
  DB_Mort_Gencomb = plyr::rbind.fill(mort_db, DB_Mort_Genalive[, -c(3:4)])
  
  #Create prism output
  if(output == "prism"){
    prism_db = data.frame(blank = rep("", nrow(DB_Mort_Gencomb)))
    
    for(col_nm in trt_levels) {
      temp_db = data.frame(ifelse(DB_Mort_Gencomb$Trt.ID == col_nm, DB_Mort_Gencomb$Status, ""))
      colnames(temp_db) = col_nm
      prism_db = cbind(prism_db, temp_db)
    }
    
    prism_db = cbind(data.frame(DB_Mort_Gencomb[, -which(colnames(DB_Mort_Gencomb) == "Status")]), 
                                prism_db[, -1])
    prism_db = data.frame(prism_db %>% arrange(Trt.ID, Tank.ID))[, -which(colnames(DB_Mort_Gencomb) == "Trt.ID")]
    
    write.csv(prism_db, "Surv_Gen Prism Survival Data.csv")
  }

  return(DB_Mort_Gencomb)
```

Label_Gen2?
```{r}
input_variables = list(Time = c("Baseline", "1wpv"),
                       Animal = c("Oysters", "Lobsters"),
                       Tissue = c("Meat", "Shell", "Water", "Head"))
n_col = 6
fill_by_row = TRUE


Label_Gen2 = function(list_input,
                      n_col = 6,
                      fil_by_row = TRUE,
                      save_name = NULL) {
  
  # Create combination data frame
  poss_grid = expand.grid(input_variables)
  
  # Sort output
  if(is.null(sort_by))
  combos = interaction(poss_grid, sep = ", ", lex.order = TRUE)
  ordered_combos = combos[order(poss_grid$Tissue)]
  extended_combos = c(paste(ordered_combos), 
                      rep("", times = ceiling(ceiling(length(ordered_combos)/n_col)/21) * 21 * n_col -
                            length(ordered_combos)))
  mat_combos = data.frame(matrix(extended_combos, ncol = n_col, byrow = fill_by_row))
  tab_combos = flextable::flextable(mat_combos, cwidth = 1.34, cheight = 1.7, use_labels = FALSE)
  tab_combos = bold(border_inner_v(border_inner_h(delete_part(
    fontsize(tab_combos, size = 9, part = "all"), part = "header"), 
    part = "all"), part = "all"), bold = TRUE, part = "all")
  
  # Save and print outputs
  print(paste("You have", length(combos), "total labels"))
  
  if(!is.null(save_name)){
    save_as_docx(tab_combos, values = list(tab_combos), path = paste(getwd(), "/Test2.docx", sep = ""),
                 pr_section = prop_section(page_size = page_size(orient = "portrait", height = 11, width = 8.5),
                                           page_margins = page_mar(bottom = 0, top = 0.25, right = 0.5, left = 0)))
    
  } else {
  
  }
  
  return(tab_combos)
}
  poss_grid = expand.grid(input_variables)
  combos = interaction(poss_grid, sep = ", ")
  ordered_combos = combos[order(poss_grid$Tissue)]
  extended_combos = c(paste(ordered_combos), 
                      rep("", times = ceiling(length(ordered_combos)/n_col) * n_col - length(ordered_combos)))
  mat_combos = data.frame(matrix(extended_combos, ncol = n_col, byrow = fill_by_row))
  
  z = regulartable(mat_combos)
  
View(mat_combos)
```

Label_Gen1
```{r}
input_variables = list(Time = c("Baseline", "1wpv"),
                       Animal = c("Oysters", "Lobsters"),
                       Tissue = c("Meat", "Shell", "Water", "Head"))
sort_by = c("Time", "Animal", "Tissue")
n_col = 6
fill_by_row = TRUE


Label_Gen = function(list_input,
                      sort_by = NULL,
                      n_col = 6,
                      fill_by_row = TRUE,
                      save_name = NULL) {
  
  # Create combination data frame
  poss_grid = expand.grid(input_variables)

  # Sort output
  if(is.null(sort_by)) {
    sort_by = names(input_variables)
  }
  rev_sb = rev(sort_by)
  for(i in rev_sb){
    poss_grid = poss_grid[order(poss_grid[, which(colnames(poss_grid) == i)]),]  
  }
  
  # Store ordered combinations
  ordered_combos = interaction(poss_grid, sep = ", ")
  extended_combos = c(paste(ordered_combos), 
                      rep("", times = ceiling(ceiling(length(ordered_combos)/n_col)/21) * 21 * n_col -
                            length(ordered_combos)))
  mat_combos = matrix(extended_combos, ncol = n_col, byrow = fill_by_row)
  colnames(mat_combos) = 1:n_col
  
  # Save and print outputs
  print(paste("You have", length(combos), "total labels"))
  
  if(is.null(save_name)){
    write.csv(x = mat_combos, file = paste("Label_Gen ", Sys.Date(), ".csv", sep = ""))
    print(paste("File saved as", paste("Label_Gen ", Sys.Date(), ".csv", sep = ""), "in", getwd()))
  } else {
    write.csv(x = mat_combos, file = paste(save_name, ".csv", sep = ""))
    print(paste("File saved as", paste(save_name, ".csv", sep = ""), "in", getwd()))
  }
}

# Summarize the input variables in a list
input_variables = list(Time = c("Baseline", "1wpv"),
                       Animal = c("Oysters", "Lobsters"),
                       Tissue = c("Meat", "Shell", "Water", "Head"))

# Run Label_Gen() using the input variables.
Label_Gen(list_input = input_variables,
          sort_by = c("Time", "Animal", "Tissue"),
          n_col = 6,
          fill_by_row = TRUE,
          save_name = NULL)
```
Methods to get surv_prob in Surv_Simul()
```{r}
  #methods to get surv_prob stored here below:
  #option 1 (old):
  #surv_prob = exp(-as.vector(apply(haz_db$hazard %*% t(treatments_hr), 2, cumsum)))

  #New method (deprecated)
  # surv_pop = data.frame()
  # for(pop_trt in levels(factor(surv_pop_old$Trt.ID))) {
  #   pop_trt_cumhaz = surv_pop_old$cumhaz_prob[surv_pop_old$Trt.ID == pop_trt]
  #   surv_prob_db = approx(x = haz_db$time, y = pop_trt_cumhaz, xout = seq(min(haz_db$time), max(haz_db$time), 0.1), method = "linear")
  #
  #   surv_pop_temp = data.frame(Trt.ID = pop_trt,
  #                              time = surv_prob_db$x,
  #                              surv_prob = exp(-surv_prob_db$y),
  #                              type = "Population / truth",
  #                              n_sim = 1,
  #                              alpha = 1)
  #   surv_pop = rbind(surv_pop, surv_pop_temp)
  # }
```

